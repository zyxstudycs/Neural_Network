{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import glob\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions, DO NOT modify this\n",
    "\n",
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imread(path)\n",
    "\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to load data, DO NOT change these\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    y_one_hot[y] = 1\n",
    "    return y_one_hot.T\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = get_img_array(f)\n",
    "        img_arr = img_arr.flatten() / 255.0\n",
    "        images.append(img_arr)\n",
    "    X = np.column_stack(images)\n",
    "\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + 'train'\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "Loaded 10000/50000\n",
      "Loaded 20000/50000\n",
      "Loaded 30000/50000\n",
      "Loaded 40000/50000\n",
      "Loaded 50000/50000\n",
      "Loaded 10000/10000\n",
      "Data loading done\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_root_path = '/Users/zhengyixing/Documents/study/3nd_semester/DL/homework/cifar10-hw1/'\n",
    "X_train, y_train = get_train_data(data_root_path) # this may take a few minutes\n",
    "X_test = get_images(data_root_path + 'test')\n",
    "print('Data loading done')\n",
    "indexs = np.random.choice(50000, 5000, replace=False)\n",
    "X_validation = X_train[:,indexs].T\n",
    "y_validation = y_train[indexs]\n",
    "X_train = np.delete(X_train,indexs, axis = 1).T\n",
    "y_train = np.delete(y_train,indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(X, y, batch_size):\n",
    "        \"\"\"\n",
    "        Return minibatch of samples and labels\n",
    "        \n",
    "        :param X, y: samples and corresponding labels\n",
    "        :parma batch_size: minibatch size\n",
    "        :returns: (tuple) X_batch, y_batch\n",
    "        \"\"\"\n",
    "        m = X.shape[1]\n",
    "        start_index = np.random.randint(0, m - batch_size)\n",
    "        X_batch = X[start_index:(start_index + batch_size), :]\n",
    "        y_batch = y[start_index:(start_index + batch_size)]\n",
    "        \n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "epoch = 50\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "with tf.name_scope('input') as scope:\n",
    "    X = tf.placeholder(tf.float32, shape = (None, 3072))\n",
    "    y = tf.placeholder(tf.int32, shape = (None))\n",
    "    dropout_rate = tf.placeholder(tf.float32, shape=())\n",
    "    training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer = tf.reshape(X, [-1, 32, 32, 3])\n",
    "\n",
    "with tf.name_scope('conv1') as scope:\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=3, strides=1, \n",
    "                            padding = 'SAME', activation = tf.nn.relu, name='conv1')\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=2, strides=2, padding='SAME', name='pool1')\n",
    "\n",
    "with tf.name_scope('conv2') as scope:\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=3, strides=1, \n",
    "                        padding = 'SAME', activation = tf.nn.relu, name='conv2')\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=2, strides=2, padding='SAME', name='pool2')\n",
    "\n",
    "with tf.name_scope('fc') as scope:\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 8*8*64], name='pool2_flat')\n",
    "    dense = tf.layers.dense(pool2_flat, units = 8*64, activation = tf.nn.relu, name='dense')\n",
    "    dropout = tf.layers.dropout(dense, rate=dropout_rate, training=training, name='dropout')\n",
    "    \n",
    "with tf.name_scope('logits') as scope:\n",
    "    logits = tf.layers.dense(dropout, units = 10, name='logits')\n",
    "    \n",
    "with tf.name_scope('loss') as scope:\n",
    "    softmax = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits, name = 'softmax')\n",
    "    loss = tf.reduce_mean(softmax, name = 'loss')    \n",
    "\n",
    "with tf.name_scope('train') as scope:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "with tf.name_scope('eval') as scope:\n",
    "    correct = tf.nn.in_top_k(logits, y, 1, name='correct')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "with tf.name_scope('summary') as scope:\n",
    "    loss_summary = tf.summary.scalar('LOSS', loss)\n",
    "    accuracy_symmary = tf.summary.scalar('ACCURACY', accuracy)\n",
    "    test_loss_summary = tf.summary.scalar('test_LOSS', loss)\n",
    "    test_accuracy_symmary = tf.summary.scalar('test_ACCURACY', accuracy)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    \n",
    "with tf.name_scope('init') as scope:\n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_validation, y_validation, batch_size, epoch):\n",
    "    training_num = X_train.shape[0]\n",
    "    iteration = training_num // batch_size\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(epoch):\n",
    "            test_loss_summary_str =  test_loss_summary.eval(feed_dict={X: X_validation, y:y_validation,\n",
    "                                                             dropout_rate:0.3, training:False})\n",
    "            test_accuracy_symmary_str = test_accuracy_symmary.eval(feed_dict={X: X_validation, y:y_validation,\n",
    "                                                             dropout_rate:0.3, training:False})\n",
    "            file_writer.add_summary(test_loss_summary_str, i)\n",
    "            file_writer.add_summary(test_accuracy_symmary_str, i)\n",
    "            \n",
    "            for j in range(iteration):\n",
    "                X_batch, y_batch = get_batch(X_train, y_train, batch_size)\n",
    "                sess.run(optimizer, feed_dict={X: X_batch, y:y_batch, dropout_rate:0.3, training:True})\n",
    "                step = j + i * iteration\n",
    "                if step % 100 == 0:\n",
    "                        loss_ = loss.eval(feed_dict={X: X_batch, y:y_batch, dropout_rate:0.3, training:False})\n",
    "                        accuracy_ = accuracy.eval(feed_dict={X: X_batch, y:y_batch,\n",
    "                                                             dropout_rate:0.3, training:False})\n",
    "                        loss_summary_str =  loss_summary.eval(feed_dict={X: X_batch, y:y_batch,\n",
    "                                                                          dropout_rate:0.3, training:False})\n",
    "                        accuracy_symmary_str = accuracy_symmary.eval(feed_dict={X: X_batch, y:y_batch,\n",
    "                                                             dropout_rate:0.3, training:False})\n",
    "                        print('after '+ str(step) + ' iterations' + \n",
    "                              'the loss is ' + str(loss_) + ', the accuracy is ' + str(accuracy_))\n",
    "                        file_writer.add_summary(loss_summary_str, step)\n",
    "                        file_writer.add_summary(accuracy_symmary_str, step)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0 iterationsthe loss is 2.31124, the accuracy is 0.078125\n",
      "after 100 iterationsthe loss is 2.29308, the accuracy is 0.15625\n",
      "after 200 iterationsthe loss is 2.2992, the accuracy is 0.125\n",
      "after 300 iterationsthe loss is 2.29343, the accuracy is 0.15625\n",
      "after 400 iterationsthe loss is 2.28602, the accuracy is 0.179688\n",
      "after 500 iterationsthe loss is 2.28324, the accuracy is 0.164062\n",
      "after 600 iterationsthe loss is 2.28562, the accuracy is 0.171875\n",
      "after 700 iterationsthe loss is 2.26635, the accuracy is 0.148438\n",
      "after 800 iterationsthe loss is 2.25132, the accuracy is 0.164062\n",
      "after 900 iterationsthe loss is 2.23672, the accuracy is 0.179688\n",
      "after 1000 iterationsthe loss is 2.25197, the accuracy is 0.226562\n",
      "after 1100 iterationsthe loss is 2.24228, the accuracy is 0.203125\n",
      "after 1200 iterationsthe loss is 2.22087, the accuracy is 0.25\n",
      "after 1300 iterationsthe loss is 2.24026, the accuracy is 0.242188\n",
      "after 1400 iterationsthe loss is 2.20165, the accuracy is 0.28125\n",
      "after 1500 iterationsthe loss is 2.2038, the accuracy is 0.234375\n",
      "after 1600 iterationsthe loss is 2.19003, the accuracy is 0.28125\n",
      "after 1700 iterationsthe loss is 2.18051, the accuracy is 0.265625\n",
      "after 1800 iterationsthe loss is 2.16797, the accuracy is 0.265625\n",
      "after 1900 iterationsthe loss is 2.1387, the accuracy is 0.328125\n",
      "after 2000 iterationsthe loss is 2.16347, the accuracy is 0.21875\n",
      "after 2100 iterationsthe loss is 2.17898, the accuracy is 0.203125\n",
      "after 2200 iterationsthe loss is 2.16757, the accuracy is 0.28125\n",
      "after 2300 iterationsthe loss is 2.08835, the accuracy is 0.242188\n",
      "after 2400 iterationsthe loss is 2.06754, the accuracy is 0.265625\n",
      "after 2500 iterationsthe loss is 2.08681, the accuracy is 0.320312\n",
      "after 2600 iterationsthe loss is 2.08042, the accuracy is 0.289062\n",
      "after 2700 iterationsthe loss is 2.01802, the accuracy is 0.414062\n",
      "after 2800 iterationsthe loss is 2.10305, the accuracy is 0.296875\n",
      "after 2900 iterationsthe loss is 2.05163, the accuracy is 0.257812\n",
      "after 3000 iterationsthe loss is 1.99951, the accuracy is 0.320312\n",
      "after 3100 iterationsthe loss is 1.99622, the accuracy is 0.28125\n",
      "after 3200 iterationsthe loss is 2.03842, the accuracy is 0.335938\n",
      "after 3300 iterationsthe loss is 1.95324, the accuracy is 0.359375\n",
      "after 3400 iterationsthe loss is 1.95454, the accuracy is 0.382812\n",
      "after 3500 iterationsthe loss is 1.96685, the accuracy is 0.28125\n",
      "after 3600 iterationsthe loss is 1.98847, the accuracy is 0.296875\n",
      "after 3700 iterationsthe loss is 1.89217, the accuracy is 0.382812\n",
      "after 3800 iterationsthe loss is 1.92061, the accuracy is 0.382812\n",
      "after 3900 iterationsthe loss is 1.86505, the accuracy is 0.351562\n",
      "after 4000 iterationsthe loss is 1.83564, the accuracy is 0.367188\n",
      "after 4100 iterationsthe loss is 1.96108, the accuracy is 0.320312\n",
      "after 4200 iterationsthe loss is 1.88725, the accuracy is 0.304688\n",
      "after 4300 iterationsthe loss is 1.83544, the accuracy is 0.40625\n",
      "after 4400 iterationsthe loss is 1.90558, the accuracy is 0.398438\n",
      "after 4500 iterationsthe loss is 1.89487, the accuracy is 0.328125\n",
      "after 4600 iterationsthe loss is 1.85533, the accuracy is 0.453125\n",
      "after 4700 iterationsthe loss is 1.84887, the accuracy is 0.375\n",
      "after 4800 iterationsthe loss is 1.82431, the accuracy is 0.429688\n",
      "after 4900 iterationsthe loss is 1.9162, the accuracy is 0.351562\n",
      "after 5000 iterationsthe loss is 1.80045, the accuracy is 0.46875\n",
      "after 5100 iterationsthe loss is 1.87259, the accuracy is 0.375\n",
      "after 5200 iterationsthe loss is 1.81652, the accuracy is 0.390625\n",
      "after 5300 iterationsthe loss is 1.81815, the accuracy is 0.335938\n",
      "after 5400 iterationsthe loss is 1.87274, the accuracy is 0.40625\n",
      "after 5500 iterationsthe loss is 1.83251, the accuracy is 0.367188\n",
      "after 5600 iterationsthe loss is 1.81343, the accuracy is 0.375\n",
      "after 5700 iterationsthe loss is 1.81625, the accuracy is 0.34375\n",
      "after 5800 iterationsthe loss is 1.76164, the accuracy is 0.367188\n",
      "after 5900 iterationsthe loss is 1.90767, the accuracy is 0.367188\n",
      "after 6000 iterationsthe loss is 1.79386, the accuracy is 0.367188\n",
      "after 6100 iterationsthe loss is 1.80951, the accuracy is 0.429688\n",
      "after 6200 iterationsthe loss is 1.77346, the accuracy is 0.359375\n",
      "after 6300 iterationsthe loss is 1.78296, the accuracy is 0.40625\n",
      "after 6400 iterationsthe loss is 1.69143, the accuracy is 0.4375\n",
      "after 6500 iterationsthe loss is 1.83473, the accuracy is 0.375\n",
      "after 6600 iterationsthe loss is 1.85681, the accuracy is 0.4375\n",
      "after 6700 iterationsthe loss is 1.70616, the accuracy is 0.390625\n",
      "after 6800 iterationsthe loss is 1.75129, the accuracy is 0.429688\n",
      "after 6900 iterationsthe loss is 1.7456, the accuracy is 0.414062\n",
      "after 7000 iterationsthe loss is 1.70334, the accuracy is 0.414062\n",
      "after 7100 iterationsthe loss is 1.71542, the accuracy is 0.453125\n",
      "after 7200 iterationsthe loss is 1.79235, the accuracy is 0.476562\n",
      "after 7300 iterationsthe loss is 1.69867, the accuracy is 0.445312\n",
      "after 7400 iterationsthe loss is 1.74036, the accuracy is 0.40625\n",
      "after 7500 iterationsthe loss is 1.80481, the accuracy is 0.382812\n",
      "after 7600 iterationsthe loss is 1.79832, the accuracy is 0.390625\n",
      "after 7700 iterationsthe loss is 1.73409, the accuracy is 0.421875\n",
      "after 7800 iterationsthe loss is 1.74752, the accuracy is 0.445312\n",
      "after 7900 iterationsthe loss is 1.75468, the accuracy is 0.40625\n",
      "after 8000 iterationsthe loss is 1.63808, the accuracy is 0.390625\n",
      "after 8100 iterationsthe loss is 1.72315, the accuracy is 0.382812\n",
      "after 8200 iterationsthe loss is 1.60828, the accuracy is 0.46875\n",
      "after 8300 iterationsthe loss is 1.63411, the accuracy is 0.453125\n",
      "after 8400 iterationsthe loss is 1.61942, the accuracy is 0.46875\n",
      "after 8500 iterationsthe loss is 1.79279, the accuracy is 0.421875\n",
      "after 8600 iterationsthe loss is 1.61674, the accuracy is 0.421875\n",
      "after 8700 iterationsthe loss is 1.61352, the accuracy is 0.453125\n",
      "after 8800 iterationsthe loss is 1.70529, the accuracy is 0.375\n",
      "after 8900 iterationsthe loss is 1.5611, the accuracy is 0.40625\n",
      "after 9000 iterationsthe loss is 1.69574, the accuracy is 0.367188\n",
      "after 9100 iterationsthe loss is 1.61667, the accuracy is 0.460938\n",
      "after 9200 iterationsthe loss is 1.53585, the accuracy is 0.476562\n",
      "after 9300 iterationsthe loss is 1.65587, the accuracy is 0.453125\n",
      "after 9400 iterationsthe loss is 1.62712, the accuracy is 0.460938\n",
      "after 9500 iterationsthe loss is 1.58475, the accuracy is 0.476562\n",
      "after 9600 iterationsthe loss is 1.52081, the accuracy is 0.515625\n",
      "after 9700 iterationsthe loss is 1.60015, the accuracy is 0.445312\n",
      "after 9800 iterationsthe loss is 1.54796, the accuracy is 0.507812\n",
      "after 9900 iterationsthe loss is 1.60037, the accuracy is 0.46875\n",
      "after 10000 iterationsthe loss is 1.54474, the accuracy is 0.492188\n",
      "after 10100 iterationsthe loss is 1.53313, the accuracy is 0.523438\n",
      "after 10200 iterationsthe loss is 1.5222, the accuracy is 0.523438\n",
      "after 10300 iterationsthe loss is 1.5612, the accuracy is 0.460938\n",
      "after 10400 iterationsthe loss is 1.54979, the accuracy is 0.476562\n",
      "after 10500 iterationsthe loss is 1.49784, the accuracy is 0.460938\n",
      "after 10600 iterationsthe loss is 1.51669, the accuracy is 0.46875\n",
      "after 10700 iterationsthe loss is 1.42459, the accuracy is 0.539062\n",
      "after 10800 iterationsthe loss is 1.6, the accuracy is 0.421875\n",
      "after 10900 iterationsthe loss is 1.42754, the accuracy is 0.546875\n",
      "after 11000 iterationsthe loss is 1.46745, the accuracy is 0.53125\n",
      "after 11100 iterationsthe loss is 1.46966, the accuracy is 0.515625\n",
      "after 11200 iterationsthe loss is 1.51691, the accuracy is 0.476562\n",
      "after 11300 iterationsthe loss is 1.51785, the accuracy is 0.484375\n",
      "after 11400 iterationsthe loss is 1.40975, the accuracy is 0.578125\n",
      "after 11500 iterationsthe loss is 1.4938, the accuracy is 0.539062\n",
      "after 11600 iterationsthe loss is 1.48079, the accuracy is 0.46875\n",
      "after 11700 iterationsthe loss is 1.4489, the accuracy is 0.5\n",
      "after 11800 iterationsthe loss is 1.56806, the accuracy is 0.507812\n",
      "after 11900 iterationsthe loss is 1.38074, the accuracy is 0.570312\n",
      "after 12000 iterationsthe loss is 1.47968, the accuracy is 0.492188\n",
      "after 12100 iterationsthe loss is 1.37705, the accuracy is 0.515625\n",
      "after 12200 iterationsthe loss is 1.47202, the accuracy is 0.507812\n",
      "after 12300 iterationsthe loss is 1.4264, the accuracy is 0.507812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 12400 iterationsthe loss is 1.42128, the accuracy is 0.546875\n",
      "after 12500 iterationsthe loss is 1.47796, the accuracy is 0.5\n",
      "after 12600 iterationsthe loss is 1.52939, the accuracy is 0.492188\n",
      "after 12700 iterationsthe loss is 1.43035, the accuracy is 0.476562\n",
      "after 12800 iterationsthe loss is 1.47373, the accuracy is 0.492188\n",
      "after 12900 iterationsthe loss is 1.39056, the accuracy is 0.578125\n",
      "after 13000 iterationsthe loss is 1.28016, the accuracy is 0.601562\n",
      "after 13100 iterationsthe loss is 1.27141, the accuracy is 0.570312\n",
      "after 13200 iterationsthe loss is 1.27697, the accuracy is 0.609375\n",
      "after 13300 iterationsthe loss is 1.30873, the accuracy is 0.476562\n",
      "after 13400 iterationsthe loss is 1.31236, the accuracy is 0.554688\n",
      "after 13500 iterationsthe loss is 1.41369, the accuracy is 0.484375\n",
      "after 13600 iterationsthe loss is 1.26127, the accuracy is 0.617188\n",
      "after 13700 iterationsthe loss is 1.30967, the accuracy is 0.601562\n",
      "after 13800 iterationsthe loss is 1.35661, the accuracy is 0.507812\n",
      "after 13900 iterationsthe loss is 1.2647, the accuracy is 0.632812\n",
      "after 14000 iterationsthe loss is 1.31039, the accuracy is 0.585938\n",
      "after 14100 iterationsthe loss is 1.36332, the accuracy is 0.554688\n",
      "after 14200 iterationsthe loss is 1.16199, the accuracy is 0.632812\n",
      "after 14300 iterationsthe loss is 1.25953, the accuracy is 0.53125\n",
      "after 14400 iterationsthe loss is 1.21243, the accuracy is 0.632812\n",
      "after 14500 iterationsthe loss is 1.29331, the accuracy is 0.59375\n",
      "after 14600 iterationsthe loss is 1.38113, the accuracy is 0.53125\n",
      "after 14700 iterationsthe loss is 1.22946, the accuracy is 0.609375\n",
      "after 14800 iterationsthe loss is 1.3565, the accuracy is 0.507812\n",
      "after 14900 iterationsthe loss is 1.19421, the accuracy is 0.617188\n",
      "after 15000 iterationsthe loss is 1.18823, the accuracy is 0.625\n",
      "after 15100 iterationsthe loss is 1.20923, the accuracy is 0.65625\n",
      "after 15200 iterationsthe loss is 1.14085, the accuracy is 0.671875\n",
      "after 15300 iterationsthe loss is 1.24213, the accuracy is 0.625\n",
      "after 15400 iterationsthe loss is 1.17133, the accuracy is 0.671875\n",
      "after 15500 iterationsthe loss is 1.18145, the accuracy is 0.65625\n",
      "after 15600 iterationsthe loss is 1.26027, the accuracy is 0.5625\n",
      "after 15700 iterationsthe loss is 1.14653, the accuracy is 0.625\n",
      "after 15800 iterationsthe loss is 1.11394, the accuracy is 0.640625\n",
      "after 15900 iterationsthe loss is 1.34815, the accuracy is 0.570312\n",
      "after 16000 iterationsthe loss is 1.13448, the accuracy is 0.640625\n",
      "after 16100 iterationsthe loss is 1.26503, the accuracy is 0.53125\n",
      "after 16200 iterationsthe loss is 1.12955, the accuracy is 0.648438\n",
      "after 16300 iterationsthe loss is 1.21232, the accuracy is 0.617188\n",
      "after 16400 iterationsthe loss is 1.06868, the accuracy is 0.679688\n",
      "after 16500 iterationsthe loss is 1.05984, the accuracy is 0.65625\n",
      "after 16600 iterationsthe loss is 1.12975, the accuracy is 0.648438\n",
      "after 16700 iterationsthe loss is 1.28824, the accuracy is 0.601562\n",
      "after 16800 iterationsthe loss is 1.07567, the accuracy is 0.648438\n",
      "after 16900 iterationsthe loss is 1.27444, the accuracy is 0.585938\n",
      "after 17000 iterationsthe loss is 1.12687, the accuracy is 0.617188\n",
      "after 17100 iterationsthe loss is 0.974048, the accuracy is 0.6875\n",
      "after 17200 iterationsthe loss is 1.13403, the accuracy is 0.664062\n",
      "after 17300 iterationsthe loss is 1.04721, the accuracy is 0.640625\n",
      "after 17400 iterationsthe loss is 1.12529, the accuracy is 0.585938\n",
      "after 17500 iterationsthe loss is 1.13616, the accuracy is 0.65625\n"
     ]
    }
   ],
   "source": [
    "train(X_train, y_train, X_validation, y_validation, batch_size, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
