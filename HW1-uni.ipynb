{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COMS 4995_002 Deep Learning Assignment 1\n",
    "Due on Monday, Oct 9, 11:59pm\n",
    "\n",
    "This assignment can be done in groups of at most 3 students. Everyone must submit on Courseworks individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the UNIs of your group (if applicable)\n",
    "\n",
    "Member 1: Name, UNI\n",
    "\n",
    "Member 2: Name, UNI\n",
    "\n",
    "Member 3: Name, UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import glob\n",
    "import sys\n",
    "# you shouldn't need to make any more imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    \"\"\"\n",
    "    Abstraction of neural network.\n",
    "    Stores parameters, activations, cached values. \n",
    "    Provides necessary functions for training and prediction. \n",
    "    \"\"\"\n",
    "    def __init__(self, layer_dimensions, drop_prob=0.0, reg_lambda=0.0):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases for each layer\n",
    "        :param layer_dimensions: (list) number of nodes in each layer\n",
    "        :param drop_prob: drop probability for dropout layers. Only required in part 2 of the assignment\n",
    "        :param reg_lambda: regularization parameter. Only required in part 2 of the assignment\n",
    "        \"\"\"\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        self.parameters = {}\n",
    "        self.num_layers =len(layer_dimensions)\n",
    "        self.drop_prob = drop_prob\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.train_cost = []\n",
    "        self.validation_cost = []\n",
    "        self.train_accuracy = []\n",
    "        self.validation_accuracy = []\n",
    "        \n",
    "        # init parameters\n",
    "        self.parameters = self.init_parameters(layer_dimensions)\n",
    "        \n",
    "    def init_parameters(self, layer_dimensions):\n",
    "        \n",
    "        parameters = {}\n",
    "        \n",
    "        for i in range(len(layer_dimensions) - 1):\n",
    "            forwoard_unit_number = layer_dimensions[i+1]\n",
    "            backwoard_unit_number = layer_dimensions[i]\n",
    "            parameters['W'+str(i+1)] = 0.01 * np.random.randn(forwoard_unit_number, backwoard_unit_number)\n",
    "            parameters['b'+str(i+1)] = np.zeros((forwoard_unit_number,1))\n",
    "            \n",
    "        return parameters\n",
    "\n",
    "    def affineForward(self, A, W, b):\n",
    "        \"\"\"\n",
    "        Forward pass for the affine layer.\n",
    "        :param A: input matrix, shape (L, S), where L is the number of hidden units in the previous layer and S is\n",
    "        the number of samples\n",
    "        :returns: the affine product WA + b, along with the cache required for the backward pass\n",
    "        \"\"\"\n",
    "        return np.dot(W, A) + b\n",
    "\n",
    "    def activationForward(self, A, activation=\"relu\"):\n",
    "        \"\"\"\n",
    "        Common interface to access all activation functions.\n",
    "        :param A: input to the activation function\n",
    "        :param prob: activation funciton to apply to A. Just \"relu\" for this assignment.\n",
    "        :returns: activation(A)\n",
    "        \"\"\" \n",
    "        return relu(A)\n",
    "\n",
    "    def relu(self, X):\n",
    "        return np.maximum(0,X)\n",
    "            \n",
    "    def dropout(self, A, prob):\n",
    "        \"\"\"\n",
    "        :param A: \n",
    "        :param prob: drop prob\n",
    "        :returns: tuple (A, M) \n",
    "            WHERE\n",
    "            A is matrix after applying dropout\n",
    "            M is dropout mask, used in the backward pass\n",
    "        \"\"\"\n",
    "        M = np.random.rand(A.shape[0], A.shape[1])\n",
    "        M = 1*(M >= prob)\n",
    "        A = np.multiply(A, M)\n",
    "        A = A / (1 - prob)\n",
    "#         print('forward dropout is working**************')\n",
    "\n",
    "        return A, M\n",
    "\n",
    "    \n",
    "    def forwardPropagation(self, X, dropout = True):\n",
    "        \"\"\"\n",
    "        Runs an input X through the neural network to compute activations\n",
    "        for all layers. Returns the output computed at the last layer along\n",
    "        with the cache required for backpropagation.\n",
    "        :returns: (tuple) AL, cache\n",
    "            WHERE \n",
    "            AL is activation of last layer\n",
    "            cache is cached values for each layer that\n",
    "                     are needed in further steps\n",
    "        \"\"\"\n",
    "        cache = {}\n",
    "        cache['A' + str(0)] = X\n",
    "        \n",
    "        for i in range(self.num_layers - 2):\n",
    "            W = self.parameters['W' + str(i+1)]\n",
    "            b = self.parameters['b' + str(i+1)]\n",
    "            A = cache['A' + str(i)]\n",
    "            Z = self.affineForward(A, W, b)\n",
    "            A_next = self.relu(Z)\n",
    "            \n",
    "            # adding dropout here\n",
    "            if self.drop_prob > 0 and dropout:\n",
    "                A_next, M = self.dropout(A_next, self.drop_prob)\n",
    "                cache['M' + str(i+1)] = M\n",
    "                \n",
    "            cache['A' + str(i+1)] = A_next\n",
    "            cache['Z' + str(i+1)] = Z\n",
    "        \n",
    "        W = self.parameters['W' + str(self.num_layers - 1)]\n",
    "        b = self.parameters['b' + str(self.num_layers - 1)]\n",
    "        AL = self.affineForward(cache['A' + str(self.num_layers - 2)], W, b)\n",
    "\n",
    "        return AL, cache\n",
    "    \n",
    "    def softmax(self, Z):\n",
    "        K = Z - np.amax(Z, axis=0)\n",
    "        K = np.exp(K)\n",
    "        sum_ = np.sum(K,axis=0, keepdims=True)\n",
    "        return K / sum_\n",
    "    \n",
    "    def costFunction(self, AL, y):\n",
    "        \"\"\"\n",
    "        :param AL: Activation of last layer, shape (num_classes, S)\n",
    "        :param y: labels, shape (S)\n",
    "        :param alpha: regularization parameter\n",
    "        :returns cost, dAL: A scalar denoting cost and the gradient of cost\n",
    "        \"\"\"\n",
    "        # compute loss\n",
    "        AL = self.softmax(AL)\n",
    "        y_one_hot = np.zeros((AL.shape[0], AL.shape[1]))\n",
    "        \n",
    "        cost = 0\n",
    "        cost = np.sum(-np.log(np.float64(AL[y, range(len(y))])))/len(y)\n",
    "        y_one_hot[y, range(len(y))] = 1\n",
    "        \n",
    "        if self.reg_lambda > 0:\n",
    "            for i in range(self.num_layers - 2):\n",
    "                W = self.parameters['W' + str(i + 1)]\n",
    "                cost += np.sum(np.multiply(W, W)) * self.reg_lambda / (2 * len(y))\n",
    "\n",
    "        dAL = AL\n",
    "        dAL[y, range(len(y))] -= 1\n",
    "    \n",
    "        #dAL = AL - y_one_hot\n",
    "    \n",
    "        return cost, dAL\n",
    "\n",
    "    def affineBackward(self, dA_prev, cache, layer_num):\n",
    "        \"\"\"\n",
    "        Backward pass for the affine layer.\n",
    "        :param dA_prev: gradient from the next layer.\n",
    "        :param cache: cache returned in affineForward\n",
    "        :returns dA: gradient on the input to this layer\n",
    "                 dW: gradient on the weights\n",
    "                 db: gradient on the bias\n",
    "        \"\"\"\n",
    "        m = dA_prev.shape[1]\n",
    "        A = cache['A' + str(layer_num-1)]\n",
    "        W = self.parameters['W' + str(layer_num)]\n",
    "        \n",
    "        #add dropout back propagation here\n",
    "        if self.drop_prob > 0:\n",
    "            dA_prev = self.dropout_backward(dA_prev, cache, layer_num)\n",
    "        \n",
    "        dZ = self.activationBackward(dA_prev, cache, layer_num)\n",
    "        dW = 1 / m * np.dot(dZ, A.T)\n",
    "        db = 1 / m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA = np.dot(W.T, dZ)\n",
    "\n",
    "        return dA, dW, db\n",
    "\n",
    "    def activationBackward(self, dA, cache, layer_num, activation=\"relu\"):\n",
    "        \"\"\"\n",
    "        Interface to call backward on activation functions.\n",
    "        In this case, it's just relu. \n",
    "        \"\"\"\n",
    "        dZ = dA * self.relu_derivative(cache['Z' + str(layer_num)])\n",
    "        return dZ\n",
    "\n",
    "        \n",
    "    def relu_derivative(self, cached_x):\n",
    "        dx = 1*(cached_x > 0)\n",
    "        return dx\n",
    "\n",
    "    def dropout_backward(self, dA, cache, layer_num):\n",
    "        M = cache['M' + str(layer_num)]\n",
    "        dA = np.multiply(M, dA) / (1 - self.drop_prob)\n",
    "#         print('backward dropout is working *********')\n",
    "        \n",
    "        return dA\n",
    "\n",
    "    def backPropagation(self, dAL, AL, cache):\n",
    "        \"\"\"\n",
    "        Run backpropagation to compute gradients on all paramters in the model\n",
    "        :param dAL: gradient on the last layer of the network. Returned by the cost function.\n",
    "        :param Y: labels\n",
    "        :param cache: cached values during forwardprop\n",
    "        :returns gradients: dW and db for each weight/bias\n",
    "        \"\"\"\n",
    "        gradients = {}\n",
    "        \n",
    "        m = AL.shape[1]\n",
    "        A = cache['A' + str(self.num_layers - 2)]\n",
    "        W = self.parameters['W' + str(self.num_layers - 1)]\n",
    "        dZ = dAL\n",
    "        dW = 1 / m * np.dot(dZ, A.T)\n",
    "        db = 1 / m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "        dA = np.dot(W.T, dZ)\n",
    "        \n",
    "        gradients['dW' + str(self.num_layers - 1)] = dW\n",
    "        gradients['db' + str(self.num_layers - 1)] = db\n",
    "        \n",
    "#         print('the dW' + str(self.num_layers - 1) + ' is' + str(np.sum(dW)/ (dW.shape[0] * dW.shape[1])))\n",
    "#         print('the db' + str(self.num_layers - 1) + ' is' + str(np.sum(db)/ (db.shape[0] * db.shape[1])))\n",
    "        \n",
    "        for layer_num in range(self.num_layers - 2, 0, -1):\n",
    "            dA, dW, db = self.affineBackward(dA, cache, layer_num)\n",
    "            gradients['dW' + str(layer_num)] = dW\n",
    "            gradients['db' + str(layer_num)] = db\n",
    "            \n",
    "#             print('the dW' + str(layer_num) + ' is' + str(np.sum(dW)/ (dW.shape[0] * dW.shape[1])))\n",
    "#             print('the db' + str(layer_num) + ' is' + str(np.sum(db)/ (db.shape[0] * db.shape[1])))\n",
    "            \n",
    "            if self.drop_prob > 0:\n",
    "                #call dropout_backward, I don't do it here... I have done that in affineBackward\n",
    "                pass\n",
    "        \n",
    "        if self.reg_lambda > 0:\n",
    "            # add gradients from L2 regularization to each dW\n",
    "            for i in range(self.num_layers - 2):\n",
    "                dW = gradients['dW' + str(i + 1)]\n",
    "                W = self.parameters['W' + str(i + 1)]\n",
    "                dW = dW + self.reg_lambda / m * W\n",
    "                gradients['dW' + str(i + 1)] = dW\n",
    "            \n",
    "        return gradients\n",
    "\n",
    "\n",
    "    def updateParameters(self, gradients, alpha):\n",
    "        \"\"\"\n",
    "        :param gradients: gradients for each weight/bias\n",
    "        :param alpha: step size for gradient descent \n",
    "        \"\"\"\n",
    "        for i in range(self.num_layers - 1):\n",
    "            W = self.parameters['W' + str(i+1)]\n",
    "            b = self.parameters['b' + str(i+1)]\n",
    "            \n",
    "            dW = gradients['dW' + str(i+1)]\n",
    "            db = gradients['db' + str(i+1)]\n",
    "            \n",
    "#             print('the dW' + str(i+1) + ' is' + str(np.sum(dW) / (dW.shape[0] * dW.shape[1])))\n",
    "#             print('the db' + str(i+1) + ' is' + str(np.sum(db)/ (db.shape[0] * db.shape[1])))\n",
    "\n",
    "\n",
    "            W -= alpha * dW\n",
    "            b -= alpha * db\n",
    "            self.parameters['W' + str(i+1)] = W\n",
    "            self.parameters['b' + str(i+1)] = b\n",
    "\n",
    "    def train(self, X, y, X_validation, y_validation, iters=1000, alpha=0.1, batch_size=100, print_every=100):\n",
    "        \"\"\"\n",
    "        :param X: input samples, each column is a sample\n",
    "        :param y: labels for input samples, y.shape[0] must equal X.shape[1]\n",
    "        :param iters: number of training iterations\n",
    "        :param alpha: step size for gradient descent\n",
    "        :param batch_size: number of samples in a minibatch\n",
    "        :param print_every: no. of iterations to print debug info after\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(0, iters):\n",
    "            # get minibatch\n",
    "            X_batch, y_batch = self.get_batch(X, y, batch_size)\n",
    "            \n",
    "            # forward prop\n",
    "            AL, cache = self.forwardPropagation(X_batch)\n",
    "            \n",
    "            # compute loss\n",
    "            cost, dAL = self.costFunction(AL, y_batch)\n",
    "            \n",
    "            # compute gradients\n",
    "            gradients = self.backPropagation(dAL, AL, cache)\n",
    "            \n",
    "            # update weights and biases based on gradient\n",
    "            self.updateParameters(gradients, alpha)\n",
    "            \n",
    "            if i % print_every == 0:\n",
    "                # print cost, train and validation set accuracies\n",
    "                train_y_predict = self.predict(X_batch)\n",
    "                train_accuracy = np.sum((train_y_predict == y_batch) * 1) / len(y_batch)\n",
    "                self.train_cost.append(cost)\n",
    "                self.train_accuracy.append(train_accuracy)\n",
    "                \n",
    "                print('the training cost after %04d iteration is %8.6f:'%(i, cost))\n",
    "                print('the training accuracy after %04d iteration is %8.2f:'%(i, train_accuracy))\n",
    "                \n",
    "                AL, _ = self.forwardPropagation(X_validation, dropout = False)\n",
    "                validation_cost, _ = self.costFunction(AL, y_validation)\n",
    "                validation_y_predict = self.predict(X_validation)\n",
    "                validation_accuracy = np.sum((validation_y_predict == y_validation) * 1) / len(y_validation)\n",
    "                self.validation_cost.append(validation_cost)\n",
    "                self.validation_accuracy.append(validation_accuracy)\n",
    "                print('the validation cost after %04d iteration is %8.6f:'%(i, validation_cost))\n",
    "                print('the validation accuracy after %04d iteration is %8.2f:'%(i, validation_accuracy)) \n",
    "    \n",
    "                            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions for each sample\n",
    "        \"\"\"\n",
    "        AL,_ = self.forwardPropagation(X, dropout = False)\n",
    "        y_pred = np.argmax(AL, axis=0)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def get_batch(self, X, y, batch_size):\n",
    "        \"\"\"\n",
    "        Return minibatch of samples and labels\n",
    "        \n",
    "        :param X, y: samples and corresponding labels\n",
    "        :parma batch_size: minibatch size\n",
    "        :returns: (tuple) X_batch, y_batch\n",
    "        \"\"\"\n",
    "        m = X.shape[1]\n",
    "        start_index = np.random.randint(0, m - batch_size)\n",
    "        X_batch = X[:, start_index:(start_index + batch_size)]\n",
    "        y_batch = y[start_index:(start_index + batch_size)]\n",
    "\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training cost after 0000 iteration is 1.513262:\n",
      "the training accuracy after 0000 iteration is     0.55:\n",
      "the validation cost after 0000 iteration is 1.588723:\n",
      "the validation accuracy after 0000 iteration is     0.41:\n",
      "the training cost after 0100 iteration is 1.393970:\n",
      "the training accuracy after 0100 iteration is     0.53:\n",
      "the validation cost after 0100 iteration is 1.521664:\n",
      "the validation accuracy after 0100 iteration is     0.45:\n",
      "the training cost after 0200 iteration is 1.816256:\n",
      "the training accuracy after 0200 iteration is     0.38:\n",
      "the validation cost after 0200 iteration is 1.501517:\n",
      "the validation accuracy after 0200 iteration is     0.45:\n",
      "the training cost after 0300 iteration is 1.480344:\n",
      "the training accuracy after 0300 iteration is     0.52:\n",
      "the validation cost after 0300 iteration is 1.494874:\n",
      "the validation accuracy after 0300 iteration is     0.46:\n",
      "the training cost after 0400 iteration is 1.458644:\n",
      "the training accuracy after 0400 iteration is     0.48:\n",
      "the validation cost after 0400 iteration is 1.482871:\n",
      "the validation accuracy after 0400 iteration is     0.46:\n",
      "the training cost after 0500 iteration is 1.539193:\n",
      "the training accuracy after 0500 iteration is     0.40:\n",
      "the validation cost after 0500 iteration is 1.488199:\n",
      "the validation accuracy after 0500 iteration is     0.46:\n",
      "the training cost after 0600 iteration is 1.431756:\n",
      "the training accuracy after 0600 iteration is     0.55:\n",
      "the validation cost after 0600 iteration is 1.490057:\n",
      "the validation accuracy after 0600 iteration is     0.47:\n",
      "the training cost after 0700 iteration is 1.526112:\n",
      "the training accuracy after 0700 iteration is     0.47:\n",
      "the validation cost after 0700 iteration is 1.486144:\n",
      "the validation accuracy after 0700 iteration is     0.47:\n",
      "the training cost after 0800 iteration is 1.332730:\n",
      "the training accuracy after 0800 iteration is     0.54:\n",
      "the validation cost after 0800 iteration is 1.477447:\n",
      "the validation accuracy after 0800 iteration is     0.46:\n",
      "the training cost after 0900 iteration is 1.599473:\n",
      "the training accuracy after 0900 iteration is     0.48:\n",
      "the validation cost after 0900 iteration is 1.464489:\n",
      "the validation accuracy after 0900 iteration is     0.47:\n",
      "the training cost after 1000 iteration is 1.420558:\n",
      "the training accuracy after 1000 iteration is     0.56:\n",
      "the validation cost after 1000 iteration is 1.513673:\n",
      "the validation accuracy after 1000 iteration is     0.45:\n",
      "the training cost after 1100 iteration is 1.382208:\n",
      "the training accuracy after 1100 iteration is     0.56:\n",
      "the validation cost after 1100 iteration is 1.473288:\n",
      "the validation accuracy after 1100 iteration is     0.47:\n",
      "the training cost after 1200 iteration is 1.471953:\n",
      "the training accuracy after 1200 iteration is     0.52:\n",
      "the validation cost after 1200 iteration is 1.456924:\n",
      "the validation accuracy after 1200 iteration is     0.48:\n",
      "the training cost after 1300 iteration is 1.378705:\n",
      "the training accuracy after 1300 iteration is     0.60:\n",
      "the validation cost after 1300 iteration is 1.503993:\n",
      "the validation accuracy after 1300 iteration is     0.46:\n",
      "the training cost after 1400 iteration is 1.510323:\n",
      "the training accuracy after 1400 iteration is     0.52:\n",
      "the validation cost after 1400 iteration is 1.458778:\n",
      "the validation accuracy after 1400 iteration is     0.47:\n",
      "the training cost after 1500 iteration is 1.396323:\n",
      "the training accuracy after 1500 iteration is     0.53:\n",
      "the validation cost after 1500 iteration is 1.445032:\n",
      "the validation accuracy after 1500 iteration is     0.47:\n",
      "the training cost after 1600 iteration is 1.418531:\n",
      "the training accuracy after 1600 iteration is     0.49:\n",
      "the validation cost after 1600 iteration is 1.470085:\n",
      "the validation accuracy after 1600 iteration is     0.48:\n",
      "the training cost after 1700 iteration is 1.354456:\n",
      "the training accuracy after 1700 iteration is     0.47:\n",
      "the validation cost after 1700 iteration is 1.443366:\n",
      "the validation accuracy after 1700 iteration is     0.48:\n",
      "the training cost after 1800 iteration is 1.392030:\n",
      "the training accuracy after 1800 iteration is     0.55:\n",
      "the validation cost after 1800 iteration is 1.472963:\n",
      "the validation accuracy after 1800 iteration is     0.47:\n",
      "the training cost after 1900 iteration is 1.451576:\n",
      "the training accuracy after 1900 iteration is     0.52:\n",
      "the validation cost after 1900 iteration is 1.482667:\n",
      "the validation accuracy after 1900 iteration is     0.47:\n",
      "the training cost after 2000 iteration is 1.388599:\n",
      "the training accuracy after 2000 iteration is     0.56:\n",
      "the validation cost after 2000 iteration is 1.418370:\n",
      "the validation accuracy after 2000 iteration is     0.49:\n",
      "the training cost after 2100 iteration is 1.335697:\n",
      "the training accuracy after 2100 iteration is     0.59:\n",
      "the validation cost after 2100 iteration is 1.428708:\n",
      "the validation accuracy after 2100 iteration is     0.48:\n",
      "the training cost after 2200 iteration is 1.468243:\n",
      "the training accuracy after 2200 iteration is     0.49:\n",
      "the validation cost after 2200 iteration is 1.458309:\n",
      "the validation accuracy after 2200 iteration is     0.48:\n",
      "the training cost after 2300 iteration is 1.490378:\n",
      "the training accuracy after 2300 iteration is     0.52:\n",
      "the validation cost after 2300 iteration is 1.447148:\n",
      "the validation accuracy after 2300 iteration is     0.48:\n",
      "the training cost after 2400 iteration is 1.477201:\n",
      "the training accuracy after 2400 iteration is     0.42:\n",
      "the validation cost after 2400 iteration is 1.476167:\n",
      "the validation accuracy after 2400 iteration is     0.48:\n",
      "the training cost after 2500 iteration is 1.472971:\n",
      "the training accuracy after 2500 iteration is     0.54:\n",
      "the validation cost after 2500 iteration is 1.430550:\n",
      "the validation accuracy after 2500 iteration is     0.49:\n",
      "the training cost after 2600 iteration is 1.527162:\n",
      "the training accuracy after 2600 iteration is     0.47:\n",
      "the validation cost after 2600 iteration is 1.454142:\n",
      "the validation accuracy after 2600 iteration is     0.48:\n",
      "the training cost after 2700 iteration is 1.315521:\n",
      "the training accuracy after 2700 iteration is     0.55:\n",
      "the validation cost after 2700 iteration is 1.430988:\n",
      "the validation accuracy after 2700 iteration is     0.49:\n",
      "the training cost after 2800 iteration is 1.341839:\n",
      "the training accuracy after 2800 iteration is     0.51:\n",
      "the validation cost after 2800 iteration is 1.469884:\n",
      "the validation accuracy after 2800 iteration is     0.48:\n",
      "the training cost after 2900 iteration is 1.295884:\n",
      "the training accuracy after 2900 iteration is     0.62:\n",
      "the validation cost after 2900 iteration is 1.419907:\n",
      "the validation accuracy after 2900 iteration is     0.49:\n",
      "the training cost after 3000 iteration is 1.347755:\n",
      "the training accuracy after 3000 iteration is     0.49:\n",
      "the validation cost after 3000 iteration is 1.453956:\n",
      "the validation accuracy after 3000 iteration is     0.48:\n",
      "the training cost after 3100 iteration is 1.188210:\n",
      "the training accuracy after 3100 iteration is     0.62:\n",
      "the validation cost after 3100 iteration is 1.394824:\n",
      "the validation accuracy after 3100 iteration is     0.51:\n",
      "the training cost after 3200 iteration is 1.332442:\n",
      "the training accuracy after 3200 iteration is     0.52:\n",
      "the validation cost after 3200 iteration is 1.396873:\n",
      "the validation accuracy after 3200 iteration is     0.50:\n",
      "the training cost after 3300 iteration is 1.424769:\n",
      "the training accuracy after 3300 iteration is     0.51:\n",
      "the validation cost after 3300 iteration is 1.388002:\n",
      "the validation accuracy after 3300 iteration is     0.50:\n",
      "the training cost after 3400 iteration is 1.104548:\n",
      "the training accuracy after 3400 iteration is     0.64:\n",
      "the validation cost after 3400 iteration is 1.404506:\n",
      "the validation accuracy after 3400 iteration is     0.49:\n",
      "the training cost after 3500 iteration is 1.401927:\n",
      "the training accuracy after 3500 iteration is     0.56:\n",
      "the validation cost after 3500 iteration is 1.397119:\n",
      "the validation accuracy after 3500 iteration is     0.50:\n",
      "the training cost after 3600 iteration is 1.442555:\n",
      "the training accuracy after 3600 iteration is     0.55:\n",
      "the validation cost after 3600 iteration is 1.396875:\n",
      "the validation accuracy after 3600 iteration is     0.50:\n",
      "the training cost after 3700 iteration is 1.233206:\n",
      "the training accuracy after 3700 iteration is     0.62:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation cost after 3700 iteration is 1.415313:\n",
      "the validation accuracy after 3700 iteration is     0.49:\n",
      "the training cost after 3800 iteration is 1.377325:\n",
      "the training accuracy after 3800 iteration is     0.54:\n",
      "the validation cost after 3800 iteration is 1.389436:\n",
      "the validation accuracy after 3800 iteration is     0.50:\n",
      "the training cost after 3900 iteration is 1.250538:\n",
      "the training accuracy after 3900 iteration is     0.68:\n",
      "the validation cost after 3900 iteration is 1.373712:\n",
      "the validation accuracy after 3900 iteration is     0.50:\n",
      "the training cost after 4000 iteration is 1.140928:\n",
      "the training accuracy after 4000 iteration is     0.66:\n",
      "the validation cost after 4000 iteration is 1.375622:\n",
      "the validation accuracy after 4000 iteration is     0.51:\n",
      "the training cost after 4100 iteration is 1.222467:\n",
      "the training accuracy after 4100 iteration is     0.55:\n",
      "the validation cost after 4100 iteration is 1.390590:\n",
      "the validation accuracy after 4100 iteration is     0.51:\n",
      "the training cost after 4200 iteration is 1.187899:\n",
      "the training accuracy after 4200 iteration is     0.62:\n",
      "the validation cost after 4200 iteration is 1.401643:\n",
      "the validation accuracy after 4200 iteration is     0.50:\n",
      "the training cost after 4300 iteration is 1.172423:\n",
      "the training accuracy after 4300 iteration is     0.66:\n",
      "the validation cost after 4300 iteration is 1.384255:\n",
      "the validation accuracy after 4300 iteration is     0.51:\n",
      "the training cost after 4400 iteration is 1.394013:\n",
      "the training accuracy after 4400 iteration is     0.52:\n",
      "the validation cost after 4400 iteration is 1.486779:\n",
      "the validation accuracy after 4400 iteration is     0.47:\n",
      "the training cost after 4500 iteration is 1.326240:\n",
      "the training accuracy after 4500 iteration is     0.62:\n",
      "the validation cost after 4500 iteration is 1.442005:\n",
      "the validation accuracy after 4500 iteration is     0.49:\n",
      "the training cost after 4600 iteration is 1.297240:\n",
      "the training accuracy after 4600 iteration is     0.64:\n",
      "the validation cost after 4600 iteration is 1.370017:\n",
      "the validation accuracy after 4600 iteration is     0.51:\n",
      "the training cost after 4700 iteration is 1.398446:\n",
      "the training accuracy after 4700 iteration is     0.57:\n",
      "the validation cost after 4700 iteration is 1.393813:\n",
      "the validation accuracy after 4700 iteration is     0.50:\n",
      "the training cost after 4800 iteration is 1.324777:\n",
      "the training accuracy after 4800 iteration is     0.56:\n",
      "the validation cost after 4800 iteration is 1.395350:\n",
      "the validation accuracy after 4800 iteration is     0.50:\n",
      "the training cost after 4900 iteration is 1.278914:\n",
      "the training accuracy after 4900 iteration is     0.59:\n",
      "the validation cost after 4900 iteration is 1.366050:\n",
      "the validation accuracy after 4900 iteration is     0.52:\n",
      "the training cost after 5000 iteration is 1.299147:\n",
      "the training accuracy after 5000 iteration is     0.56:\n",
      "the validation cost after 5000 iteration is 1.393630:\n",
      "the validation accuracy after 5000 iteration is     0.50:\n",
      "the training cost after 5100 iteration is 1.208624:\n",
      "the training accuracy after 5100 iteration is     0.64:\n",
      "the validation cost after 5100 iteration is 1.398464:\n",
      "the validation accuracy after 5100 iteration is     0.50:\n",
      "the training cost after 5200 iteration is 1.366220:\n",
      "the training accuracy after 5200 iteration is     0.52:\n",
      "the validation cost after 5200 iteration is 1.349257:\n",
      "the validation accuracy after 5200 iteration is     0.52:\n",
      "the training cost after 5300 iteration is 1.294340:\n",
      "the training accuracy after 5300 iteration is     0.60:\n",
      "the validation cost after 5300 iteration is 1.351305:\n",
      "the validation accuracy after 5300 iteration is     0.52:\n",
      "the training cost after 5400 iteration is 1.244469:\n",
      "the training accuracy after 5400 iteration is     0.55:\n",
      "the validation cost after 5400 iteration is 1.396521:\n",
      "the validation accuracy after 5400 iteration is     0.50:\n",
      "the training cost after 5500 iteration is 1.289715:\n",
      "the training accuracy after 5500 iteration is     0.60:\n",
      "the validation cost after 5500 iteration is 1.388528:\n",
      "the validation accuracy after 5500 iteration is     0.50:\n",
      "the training cost after 5600 iteration is 1.183187:\n",
      "the training accuracy after 5600 iteration is     0.60:\n",
      "the validation cost after 5600 iteration is 1.356075:\n",
      "the validation accuracy after 5600 iteration is     0.52:\n",
      "the training cost after 5700 iteration is 1.242105:\n",
      "the training accuracy after 5700 iteration is     0.58:\n",
      "the validation cost after 5700 iteration is 1.427923:\n",
      "the validation accuracy after 5700 iteration is     0.50:\n",
      "the training cost after 5800 iteration is 1.407165:\n",
      "the training accuracy after 5800 iteration is     0.58:\n",
      "the validation cost after 5800 iteration is 1.374808:\n",
      "the validation accuracy after 5800 iteration is     0.51:\n",
      "the training cost after 5900 iteration is 1.156706:\n",
      "the training accuracy after 5900 iteration is     0.64:\n",
      "the validation cost after 5900 iteration is 1.345793:\n",
      "the validation accuracy after 5900 iteration is     0.53:\n",
      "the training cost after 6000 iteration is 1.235654:\n",
      "the training accuracy after 6000 iteration is     0.59:\n",
      "the validation cost after 6000 iteration is 1.380612:\n",
      "the validation accuracy after 6000 iteration is     0.52:\n",
      "the training cost after 6100 iteration is 1.280186:\n",
      "the training accuracy after 6100 iteration is     0.65:\n",
      "the validation cost after 6100 iteration is 1.373889:\n",
      "the validation accuracy after 6100 iteration is     0.52:\n",
      "the training cost after 6200 iteration is 1.107426:\n",
      "the training accuracy after 6200 iteration is     0.67:\n",
      "the validation cost after 6200 iteration is 1.375702:\n",
      "the validation accuracy after 6200 iteration is     0.52:\n",
      "the training cost after 6300 iteration is 1.404242:\n",
      "the training accuracy after 6300 iteration is     0.49:\n",
      "the validation cost after 6300 iteration is 1.388574:\n",
      "the validation accuracy after 6300 iteration is     0.52:\n",
      "the training cost after 6400 iteration is 1.257916:\n",
      "the training accuracy after 6400 iteration is     0.58:\n",
      "the validation cost after 6400 iteration is 1.375288:\n",
      "the validation accuracy after 6400 iteration is     0.52:\n",
      "the training cost after 6500 iteration is 1.206834:\n",
      "the training accuracy after 6500 iteration is     0.66:\n",
      "the validation cost after 6500 iteration is 1.370112:\n",
      "the validation accuracy after 6500 iteration is     0.51:\n",
      "the training cost after 6600 iteration is 1.257267:\n",
      "the training accuracy after 6600 iteration is     0.62:\n",
      "the validation cost after 6600 iteration is 1.399787:\n",
      "the validation accuracy after 6600 iteration is     0.50:\n",
      "the training cost after 6700 iteration is 1.048320:\n",
      "the training accuracy after 6700 iteration is     0.70:\n",
      "the validation cost after 6700 iteration is 1.410070:\n",
      "the validation accuracy after 6700 iteration is     0.51:\n",
      "the training cost after 6800 iteration is 1.341244:\n",
      "the training accuracy after 6800 iteration is     0.57:\n",
      "the validation cost after 6800 iteration is 1.381843:\n",
      "the validation accuracy after 6800 iteration is     0.51:\n",
      "the training cost after 6900 iteration is 0.987831:\n",
      "the training accuracy after 6900 iteration is     0.72:\n",
      "the validation cost after 6900 iteration is 1.391749:\n",
      "the validation accuracy after 6900 iteration is     0.51:\n",
      "the training cost after 7000 iteration is 1.177050:\n",
      "the training accuracy after 7000 iteration is     0.63:\n",
      "the validation cost after 7000 iteration is 1.375418:\n",
      "the validation accuracy after 7000 iteration is     0.52:\n",
      "the training cost after 7100 iteration is 1.430385:\n",
      "the training accuracy after 7100 iteration is     0.62:\n",
      "the validation cost after 7100 iteration is 1.373869:\n",
      "the validation accuracy after 7100 iteration is     0.52:\n",
      "the training cost after 7200 iteration is 1.140436:\n",
      "the training accuracy after 7200 iteration is     0.68:\n",
      "the validation cost after 7200 iteration is 1.399460:\n",
      "the validation accuracy after 7200 iteration is     0.51:\n",
      "the training cost after 7300 iteration is 1.122026:\n",
      "the training accuracy after 7300 iteration is     0.66:\n",
      "the validation cost after 7300 iteration is 1.361601:\n",
      "the validation accuracy after 7300 iteration is     0.52:\n",
      "the training cost after 7400 iteration is 1.317146:\n",
      "the training accuracy after 7400 iteration is     0.59:\n",
      "the validation cost after 7400 iteration is 1.335251:\n",
      "the validation accuracy after 7400 iteration is     0.54:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training cost after 7500 iteration is 1.079454:\n",
      "the training accuracy after 7500 iteration is     0.69:\n",
      "the validation cost after 7500 iteration is 1.321434:\n",
      "the validation accuracy after 7500 iteration is     0.54:\n",
      "the training cost after 7600 iteration is 1.335546:\n",
      "the training accuracy after 7600 iteration is     0.57:\n",
      "the validation cost after 7600 iteration is 1.352203:\n",
      "the validation accuracy after 7600 iteration is     0.53:\n",
      "the training cost after 7700 iteration is 1.255085:\n",
      "the training accuracy after 7700 iteration is     0.59:\n",
      "the validation cost after 7700 iteration is 1.334385:\n",
      "the validation accuracy after 7700 iteration is     0.53:\n",
      "the training cost after 7800 iteration is 1.133412:\n",
      "the training accuracy after 7800 iteration is     0.65:\n",
      "the validation cost after 7800 iteration is 1.380945:\n",
      "the validation accuracy after 7800 iteration is     0.51:\n",
      "the training cost after 7900 iteration is 1.215034:\n",
      "the training accuracy after 7900 iteration is     0.59:\n",
      "the validation cost after 7900 iteration is 1.362045:\n",
      "the validation accuracy after 7900 iteration is     0.51:\n",
      "the training cost after 8000 iteration is 1.175373:\n",
      "the training accuracy after 8000 iteration is     0.63:\n",
      "the validation cost after 8000 iteration is 1.338692:\n",
      "the validation accuracy after 8000 iteration is     0.53:\n",
      "the training cost after 8100 iteration is 1.084007:\n",
      "the training accuracy after 8100 iteration is     0.67:\n",
      "the validation cost after 8100 iteration is 1.360790:\n",
      "the validation accuracy after 8100 iteration is     0.52:\n",
      "the training cost after 8200 iteration is 1.273198:\n",
      "the training accuracy after 8200 iteration is     0.63:\n",
      "the validation cost after 8200 iteration is 1.381048:\n",
      "the validation accuracy after 8200 iteration is     0.51:\n",
      "the training cost after 8300 iteration is 1.147016:\n",
      "the training accuracy after 8300 iteration is     0.62:\n",
      "the validation cost after 8300 iteration is 1.351764:\n",
      "the validation accuracy after 8300 iteration is     0.53:\n",
      "the training cost after 8400 iteration is 1.321119:\n",
      "the training accuracy after 8400 iteration is     0.62:\n",
      "the validation cost after 8400 iteration is 1.411905:\n",
      "the validation accuracy after 8400 iteration is     0.52:\n",
      "the training cost after 8500 iteration is 1.053738:\n",
      "the training accuracy after 8500 iteration is     0.66:\n",
      "the validation cost after 8500 iteration is 1.388510:\n",
      "the validation accuracy after 8500 iteration is     0.51:\n",
      "the training cost after 8600 iteration is 1.054046:\n",
      "the training accuracy after 8600 iteration is     0.73:\n",
      "the validation cost after 8600 iteration is 1.365855:\n",
      "the validation accuracy after 8600 iteration is     0.52:\n",
      "the training cost after 8700 iteration is 1.062037:\n",
      "the training accuracy after 8700 iteration is     0.69:\n",
      "the validation cost after 8700 iteration is 1.392181:\n",
      "the validation accuracy after 8700 iteration is     0.52:\n",
      "the training cost after 8800 iteration is 1.333265:\n",
      "the training accuracy after 8800 iteration is     0.59:\n",
      "the validation cost after 8800 iteration is 1.393178:\n",
      "the validation accuracy after 8800 iteration is     0.51:\n",
      "the training cost after 8900 iteration is 0.891728:\n",
      "the training accuracy after 8900 iteration is     0.79:\n",
      "the validation cost after 8900 iteration is 1.353808:\n",
      "the validation accuracy after 8900 iteration is     0.53:\n",
      "the training cost after 9000 iteration is 1.280946:\n",
      "the training accuracy after 9000 iteration is     0.62:\n",
      "the validation cost after 9000 iteration is 1.367853:\n",
      "the validation accuracy after 9000 iteration is     0.52:\n",
      "the training cost after 9100 iteration is 1.022946:\n",
      "the training accuracy after 9100 iteration is     0.71:\n",
      "the validation cost after 9100 iteration is 1.352192:\n",
      "the validation accuracy after 9100 iteration is     0.53:\n",
      "the training cost after 9200 iteration is 1.094515:\n",
      "the training accuracy after 9200 iteration is     0.66:\n",
      "the validation cost after 9200 iteration is 1.360475:\n",
      "the validation accuracy after 9200 iteration is     0.53:\n",
      "the training cost after 9300 iteration is 1.131565:\n",
      "the training accuracy after 9300 iteration is     0.66:\n",
      "the validation cost after 9300 iteration is 1.390224:\n",
      "the validation accuracy after 9300 iteration is     0.52:\n",
      "the training cost after 9400 iteration is 1.074482:\n",
      "the training accuracy after 9400 iteration is     0.70:\n",
      "the validation cost after 9400 iteration is 1.333626:\n",
      "the validation accuracy after 9400 iteration is     0.53:\n",
      "the training cost after 9500 iteration is 1.069534:\n",
      "the training accuracy after 9500 iteration is     0.68:\n",
      "the validation cost after 9500 iteration is 1.327031:\n",
      "the validation accuracy after 9500 iteration is     0.53:\n",
      "the training cost after 9600 iteration is 1.226696:\n",
      "the training accuracy after 9600 iteration is     0.65:\n",
      "the validation cost after 9600 iteration is 1.396772:\n",
      "the validation accuracy after 9600 iteration is     0.51:\n",
      "the training cost after 9700 iteration is 1.356389:\n",
      "the training accuracy after 9700 iteration is     0.65:\n",
      "the validation cost after 9700 iteration is 1.357603:\n",
      "the validation accuracy after 9700 iteration is     0.52:\n",
      "the training cost after 9800 iteration is 1.181102:\n",
      "the training accuracy after 9800 iteration is     0.62:\n",
      "the validation cost after 9800 iteration is 1.347056:\n",
      "the validation accuracy after 9800 iteration is     0.52:\n",
      "the training cost after 9900 iteration is 1.084906:\n",
      "the training accuracy after 9900 iteration is     0.70:\n",
      "the validation cost after 9900 iteration is 1.337827:\n",
      "the validation accuracy after 9900 iteration is     0.54:\n",
      "the training cost after 10000 iteration is 1.076146:\n",
      "the training accuracy after 10000 iteration is     0.70:\n",
      "the validation cost after 10000 iteration is 1.354215:\n",
      "the validation accuracy after 10000 iteration is     0.54:\n",
      "the training cost after 10100 iteration is 1.011782:\n",
      "the training accuracy after 10100 iteration is     0.70:\n",
      "the validation cost after 10100 iteration is 1.406581:\n",
      "the validation accuracy after 10100 iteration is     0.51:\n",
      "the training cost after 10200 iteration is 1.107591:\n",
      "the training accuracy after 10200 iteration is     0.64:\n",
      "the validation cost after 10200 iteration is 1.388721:\n",
      "the validation accuracy after 10200 iteration is     0.51:\n",
      "the training cost after 10300 iteration is 1.169241:\n",
      "the training accuracy after 10300 iteration is     0.64:\n",
      "the validation cost after 10300 iteration is 1.372121:\n",
      "the validation accuracy after 10300 iteration is     0.52:\n",
      "the training cost after 10400 iteration is 0.995038:\n",
      "the training accuracy after 10400 iteration is     0.66:\n",
      "the validation cost after 10400 iteration is 1.317507:\n",
      "the validation accuracy after 10400 iteration is     0.54:\n",
      "the training cost after 10500 iteration is 0.880727:\n",
      "the training accuracy after 10500 iteration is     0.77:\n",
      "the validation cost after 10500 iteration is 1.386444:\n",
      "the validation accuracy after 10500 iteration is     0.52:\n",
      "the training cost after 10600 iteration is 1.002066:\n",
      "the training accuracy after 10600 iteration is     0.70:\n",
      "the validation cost after 10600 iteration is 1.313202:\n",
      "the validation accuracy after 10600 iteration is     0.54:\n",
      "the training cost after 10700 iteration is 1.160268:\n",
      "the training accuracy after 10700 iteration is     0.71:\n",
      "the validation cost after 10700 iteration is 1.333825:\n",
      "the validation accuracy after 10700 iteration is     0.54:\n",
      "the training cost after 10800 iteration is 1.235809:\n",
      "the training accuracy after 10800 iteration is     0.66:\n",
      "the validation cost after 10800 iteration is 1.496103:\n",
      "the validation accuracy after 10800 iteration is     0.49:\n",
      "the training cost after 10900 iteration is 1.019357:\n",
      "the training accuracy after 10900 iteration is     0.69:\n",
      "the validation cost after 10900 iteration is 1.384450:\n",
      "the validation accuracy after 10900 iteration is     0.53:\n",
      "the training cost after 11000 iteration is 1.011740:\n",
      "the training accuracy after 11000 iteration is     0.73:\n",
      "the validation cost after 11000 iteration is 1.360207:\n",
      "the validation accuracy after 11000 iteration is     0.53:\n",
      "the training cost after 11100 iteration is 1.055311:\n",
      "the training accuracy after 11100 iteration is     0.76:\n",
      "the validation cost after 11100 iteration is 1.345546:\n",
      "the validation accuracy after 11100 iteration is     0.54:\n",
      "the training cost after 11200 iteration is 1.035258:\n",
      "the training accuracy after 11200 iteration is     0.67:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation cost after 11200 iteration is 1.373247:\n",
      "the validation accuracy after 11200 iteration is     0.53:\n",
      "the training cost after 11300 iteration is 1.051271:\n",
      "the training accuracy after 11300 iteration is     0.75:\n",
      "the validation cost after 11300 iteration is 1.365598:\n",
      "the validation accuracy after 11300 iteration is     0.53:\n",
      "the training cost after 11400 iteration is 1.215484:\n",
      "the training accuracy after 11400 iteration is     0.68:\n",
      "the validation cost after 11400 iteration is 1.343812:\n",
      "the validation accuracy after 11400 iteration is     0.53:\n",
      "the training cost after 11500 iteration is 0.965352:\n",
      "the training accuracy after 11500 iteration is     0.70:\n",
      "the validation cost after 11500 iteration is 1.364309:\n",
      "the validation accuracy after 11500 iteration is     0.54:\n",
      "the training cost after 11600 iteration is 1.073021:\n",
      "the training accuracy after 11600 iteration is     0.67:\n",
      "the validation cost after 11600 iteration is 1.328445:\n",
      "the validation accuracy after 11600 iteration is     0.54:\n",
      "the training cost after 11700 iteration is 1.017704:\n",
      "the training accuracy after 11700 iteration is     0.70:\n",
      "the validation cost after 11700 iteration is 1.341333:\n",
      "the validation accuracy after 11700 iteration is     0.54:\n",
      "the training cost after 11800 iteration is 0.878585:\n",
      "the training accuracy after 11800 iteration is     0.78:\n",
      "the validation cost after 11800 iteration is 1.386497:\n",
      "the validation accuracy after 11800 iteration is     0.53:\n",
      "the training cost after 11900 iteration is 1.156367:\n",
      "the training accuracy after 11900 iteration is     0.68:\n",
      "the validation cost after 11900 iteration is 1.345489:\n",
      "the validation accuracy after 11900 iteration is     0.54:\n",
      "the training cost after 12000 iteration is 0.893766:\n",
      "the training accuracy after 12000 iteration is     0.77:\n",
      "the validation cost after 12000 iteration is 1.356891:\n",
      "the validation accuracy after 12000 iteration is     0.53:\n",
      "the training cost after 12100 iteration is 1.196423:\n",
      "the training accuracy after 12100 iteration is     0.67:\n",
      "the validation cost after 12100 iteration is 1.407317:\n",
      "the validation accuracy after 12100 iteration is     0.51:\n",
      "the training cost after 12200 iteration is 1.043940:\n",
      "the training accuracy after 12200 iteration is     0.76:\n",
      "the validation cost after 12200 iteration is 1.322627:\n",
      "the validation accuracy after 12200 iteration is     0.54:\n",
      "the training cost after 12300 iteration is 0.806902:\n",
      "the training accuracy after 12300 iteration is     0.84:\n",
      "the validation cost after 12300 iteration is 1.337641:\n",
      "the validation accuracy after 12300 iteration is     0.54:\n",
      "the training cost after 12400 iteration is 0.746341:\n",
      "the training accuracy after 12400 iteration is     0.84:\n",
      "the validation cost after 12400 iteration is 1.310938:\n",
      "the validation accuracy after 12400 iteration is     0.55:\n",
      "the training cost after 12500 iteration is 1.250507:\n",
      "the training accuracy after 12500 iteration is     0.66:\n",
      "the validation cost after 12500 iteration is 1.370132:\n",
      "the validation accuracy after 12500 iteration is     0.52:\n",
      "the training cost after 12600 iteration is 0.956234:\n",
      "the training accuracy after 12600 iteration is     0.77:\n",
      "the validation cost after 12600 iteration is 1.382767:\n",
      "the validation accuracy after 12600 iteration is     0.53:\n",
      "the training cost after 12700 iteration is 0.887043:\n",
      "the training accuracy after 12700 iteration is     0.77:\n",
      "the validation cost after 12700 iteration is 1.380972:\n",
      "the validation accuracy after 12700 iteration is     0.53:\n",
      "the training cost after 12800 iteration is 1.142919:\n",
      "the training accuracy after 12800 iteration is     0.72:\n",
      "the validation cost after 12800 iteration is 1.335824:\n",
      "the validation accuracy after 12800 iteration is     0.53:\n",
      "the training cost after 12900 iteration is 1.003367:\n",
      "the training accuracy after 12900 iteration is     0.72:\n",
      "the validation cost after 12900 iteration is 1.365385:\n",
      "the validation accuracy after 12900 iteration is     0.53:\n",
      "the training cost after 13000 iteration is 0.988354:\n",
      "the training accuracy after 13000 iteration is     0.69:\n",
      "the validation cost after 13000 iteration is 1.484078:\n",
      "the validation accuracy after 13000 iteration is     0.50:\n",
      "the training cost after 13100 iteration is 1.175910:\n",
      "the training accuracy after 13100 iteration is     0.66:\n",
      "the validation cost after 13100 iteration is 1.459934:\n",
      "the validation accuracy after 13100 iteration is     0.49:\n",
      "the training cost after 13200 iteration is 0.891928:\n",
      "the training accuracy after 13200 iteration is     0.74:\n",
      "the validation cost after 13200 iteration is 1.360076:\n",
      "the validation accuracy after 13200 iteration is     0.54:\n",
      "the training cost after 13300 iteration is 0.797311:\n",
      "the training accuracy after 13300 iteration is     0.82:\n",
      "the validation cost after 13300 iteration is 1.364549:\n",
      "the validation accuracy after 13300 iteration is     0.54:\n",
      "the training cost after 13400 iteration is 1.088665:\n",
      "the training accuracy after 13400 iteration is     0.70:\n",
      "the validation cost after 13400 iteration is 1.375190:\n",
      "the validation accuracy after 13400 iteration is     0.52:\n",
      "the training cost after 13500 iteration is 1.003221:\n",
      "the training accuracy after 13500 iteration is     0.76:\n",
      "the validation cost after 13500 iteration is 1.329245:\n",
      "the validation accuracy after 13500 iteration is     0.53:\n",
      "the training cost after 13600 iteration is 1.016093:\n",
      "the training accuracy after 13600 iteration is     0.73:\n",
      "the validation cost after 13600 iteration is 1.344900:\n",
      "the validation accuracy after 13600 iteration is     0.54:\n",
      "the training cost after 13700 iteration is 0.953089:\n",
      "the training accuracy after 13700 iteration is     0.80:\n",
      "the validation cost after 13700 iteration is 1.384159:\n",
      "the validation accuracy after 13700 iteration is     0.53:\n",
      "the training cost after 13800 iteration is 1.165904:\n",
      "the training accuracy after 13800 iteration is     0.63:\n",
      "the validation cost after 13800 iteration is 1.448369:\n",
      "the validation accuracy after 13800 iteration is     0.51:\n",
      "the training cost after 13900 iteration is 0.897863:\n",
      "the training accuracy after 13900 iteration is     0.77:\n",
      "the validation cost after 13900 iteration is 1.377738:\n",
      "the validation accuracy after 13900 iteration is     0.54:\n",
      "the training cost after 14000 iteration is 0.860879:\n",
      "the training accuracy after 14000 iteration is     0.78:\n",
      "the validation cost after 14000 iteration is 1.329800:\n",
      "the validation accuracy after 14000 iteration is     0.55:\n",
      "the training cost after 14100 iteration is 0.808029:\n",
      "the training accuracy after 14100 iteration is     0.80:\n",
      "the validation cost after 14100 iteration is 1.355262:\n",
      "the validation accuracy after 14100 iteration is     0.54:\n",
      "the training cost after 14200 iteration is 0.928769:\n",
      "the training accuracy after 14200 iteration is     0.77:\n",
      "the validation cost after 14200 iteration is 1.306462:\n",
      "the validation accuracy after 14200 iteration is     0.55:\n",
      "the training cost after 14300 iteration is 1.044659:\n",
      "the training accuracy after 14300 iteration is     0.69:\n",
      "the validation cost after 14300 iteration is 1.498082:\n",
      "the validation accuracy after 14300 iteration is     0.50:\n",
      "the training cost after 14400 iteration is 0.945822:\n",
      "the training accuracy after 14400 iteration is     0.73:\n",
      "the validation cost after 14400 iteration is 1.394915:\n",
      "the validation accuracy after 14400 iteration is     0.53:\n",
      "the training cost after 14500 iteration is 0.888571:\n",
      "the training accuracy after 14500 iteration is     0.75:\n",
      "the validation cost after 14500 iteration is 1.354313:\n",
      "the validation accuracy after 14500 iteration is     0.55:\n",
      "the training cost after 14600 iteration is 0.726787:\n",
      "the training accuracy after 14600 iteration is     0.83:\n",
      "the validation cost after 14600 iteration is 1.383469:\n",
      "the validation accuracy after 14600 iteration is     0.54:\n",
      "the training cost after 14700 iteration is 1.020197:\n",
      "the training accuracy after 14700 iteration is     0.69:\n",
      "the validation cost after 14700 iteration is 1.351859:\n",
      "the validation accuracy after 14700 iteration is     0.54:\n",
      "the training cost after 14800 iteration is 1.087749:\n",
      "the training accuracy after 14800 iteration is     0.73:\n",
      "the validation cost after 14800 iteration is 1.467525:\n",
      "the validation accuracy after 14800 iteration is     0.51:\n",
      "the training cost after 14900 iteration is 0.753488:\n",
      "the training accuracy after 14900 iteration is     0.80:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation cost after 14900 iteration is 1.340100:\n",
      "the validation accuracy after 14900 iteration is     0.55:\n",
      "the training cost after 15000 iteration is 0.966475:\n",
      "the training accuracy after 15000 iteration is     0.76:\n",
      "the validation cost after 15000 iteration is 1.406416:\n",
      "the validation accuracy after 15000 iteration is     0.54:\n",
      "the training cost after 15100 iteration is 0.970128:\n",
      "the training accuracy after 15100 iteration is     0.73:\n",
      "the validation cost after 15100 iteration is 1.431855:\n",
      "the validation accuracy after 15100 iteration is     0.52:\n",
      "the training cost after 15200 iteration is 1.056158:\n",
      "the training accuracy after 15200 iteration is     0.77:\n",
      "the validation cost after 15200 iteration is 1.399715:\n",
      "the validation accuracy after 15200 iteration is     0.53:\n",
      "the training cost after 15300 iteration is 1.077465:\n",
      "the training accuracy after 15300 iteration is     0.66:\n",
      "the validation cost after 15300 iteration is 1.515327:\n",
      "the validation accuracy after 15300 iteration is     0.50:\n",
      "the training cost after 15400 iteration is 1.062215:\n",
      "the training accuracy after 15400 iteration is     0.76:\n",
      "the validation cost after 15400 iteration is 1.371623:\n",
      "the validation accuracy after 15400 iteration is     0.54:\n",
      "the training cost after 15500 iteration is 0.972748:\n",
      "the training accuracy after 15500 iteration is     0.80:\n",
      "the validation cost after 15500 iteration is 1.385872:\n",
      "the validation accuracy after 15500 iteration is     0.53:\n",
      "the training cost after 15600 iteration is 1.161783:\n",
      "the training accuracy after 15600 iteration is     0.66:\n",
      "the validation cost after 15600 iteration is 1.348343:\n",
      "the validation accuracy after 15600 iteration is     0.53:\n",
      "the training cost after 15700 iteration is 0.887067:\n",
      "the training accuracy after 15700 iteration is     0.80:\n",
      "the validation cost after 15700 iteration is 1.374285:\n",
      "the validation accuracy after 15700 iteration is     0.53:\n",
      "the training cost after 15800 iteration is 0.942113:\n",
      "the training accuracy after 15800 iteration is     0.76:\n",
      "the validation cost after 15800 iteration is 1.390565:\n",
      "the validation accuracy after 15800 iteration is     0.53:\n",
      "the training cost after 15900 iteration is 1.130633:\n",
      "the training accuracy after 15900 iteration is     0.78:\n",
      "the validation cost after 15900 iteration is 1.415627:\n",
      "the validation accuracy after 15900 iteration is     0.53:\n",
      "the training cost after 16000 iteration is 0.781249:\n",
      "the training accuracy after 16000 iteration is     0.83:\n",
      "the validation cost after 16000 iteration is 1.318445:\n",
      "the validation accuracy after 16000 iteration is     0.56:\n",
      "the training cost after 16100 iteration is 0.888077:\n",
      "the training accuracy after 16100 iteration is     0.76:\n",
      "the validation cost after 16100 iteration is 1.472004:\n",
      "the validation accuracy after 16100 iteration is     0.52:\n",
      "the training cost after 16200 iteration is 0.755914:\n",
      "the training accuracy after 16200 iteration is     0.84:\n",
      "the validation cost after 16200 iteration is 1.410287:\n",
      "the validation accuracy after 16200 iteration is     0.54:\n",
      "the training cost after 16300 iteration is 0.891173:\n",
      "the training accuracy after 16300 iteration is     0.78:\n",
      "the validation cost after 16300 iteration is 1.381129:\n",
      "the validation accuracy after 16300 iteration is     0.54:\n",
      "the training cost after 16400 iteration is 0.804464:\n",
      "the training accuracy after 16400 iteration is     0.78:\n",
      "the validation cost after 16400 iteration is 1.377658:\n",
      "the validation accuracy after 16400 iteration is     0.55:\n",
      "the training cost after 16500 iteration is 1.052342:\n",
      "the training accuracy after 16500 iteration is     0.77:\n",
      "the validation cost after 16500 iteration is 1.400398:\n",
      "the validation accuracy after 16500 iteration is     0.54:\n",
      "the training cost after 16600 iteration is 0.808101:\n",
      "the training accuracy after 16600 iteration is     0.77:\n",
      "the validation cost after 16600 iteration is 1.483077:\n",
      "the validation accuracy after 16600 iteration is     0.53:\n",
      "the training cost after 16700 iteration is 0.978147:\n",
      "the training accuracy after 16700 iteration is     0.80:\n",
      "the validation cost after 16700 iteration is 1.394638:\n",
      "the validation accuracy after 16700 iteration is     0.53:\n",
      "the training cost after 16800 iteration is 0.916305:\n",
      "the training accuracy after 16800 iteration is     0.81:\n",
      "the validation cost after 16800 iteration is 1.384192:\n",
      "the validation accuracy after 16800 iteration is     0.54:\n",
      "the training cost after 16900 iteration is 0.861670:\n",
      "the training accuracy after 16900 iteration is     0.82:\n",
      "the validation cost after 16900 iteration is 1.493006:\n",
      "the validation accuracy after 16900 iteration is     0.53:\n",
      "the training cost after 17000 iteration is 0.996879:\n",
      "the training accuracy after 17000 iteration is     0.82:\n",
      "the validation cost after 17000 iteration is 1.362199:\n",
      "the validation accuracy after 17000 iteration is     0.54:\n",
      "the training cost after 17100 iteration is 0.857567:\n",
      "the training accuracy after 17100 iteration is     0.77:\n",
      "the validation cost after 17100 iteration is 1.400040:\n",
      "the validation accuracy after 17100 iteration is     0.54:\n",
      "the training cost after 17200 iteration is 0.970242:\n",
      "the training accuracy after 17200 iteration is     0.71:\n",
      "the validation cost after 17200 iteration is 1.338708:\n",
      "the validation accuracy after 17200 iteration is     0.55:\n",
      "the training cost after 17300 iteration is 0.870629:\n",
      "the training accuracy after 17300 iteration is     0.82:\n",
      "the validation cost after 17300 iteration is 1.390955:\n",
      "the validation accuracy after 17300 iteration is     0.54:\n",
      "the training cost after 17400 iteration is 0.762800:\n",
      "the training accuracy after 17400 iteration is     0.83:\n",
      "the validation cost after 17400 iteration is 1.337949:\n",
      "the validation accuracy after 17400 iteration is     0.55:\n",
      "the training cost after 17500 iteration is 0.744628:\n",
      "the training accuracy after 17500 iteration is     0.82:\n",
      "the validation cost after 17500 iteration is 1.408032:\n",
      "the validation accuracy after 17500 iteration is     0.54:\n",
      "the training cost after 17600 iteration is 0.736241:\n",
      "the training accuracy after 17600 iteration is     0.84:\n",
      "the validation cost after 17600 iteration is 1.413012:\n",
      "the validation accuracy after 17600 iteration is     0.53:\n",
      "the training cost after 17700 iteration is 0.946025:\n",
      "the training accuracy after 17700 iteration is     0.74:\n",
      "the validation cost after 17700 iteration is 1.399913:\n",
      "the validation accuracy after 17700 iteration is     0.54:\n",
      "the training cost after 17800 iteration is 0.903066:\n",
      "the training accuracy after 17800 iteration is     0.71:\n",
      "the validation cost after 17800 iteration is 1.702240:\n",
      "the validation accuracy after 17800 iteration is     0.49:\n",
      "the training cost after 17900 iteration is 0.954987:\n",
      "the training accuracy after 17900 iteration is     0.84:\n",
      "the validation cost after 17900 iteration is 1.428567:\n",
      "the validation accuracy after 17900 iteration is     0.54:\n",
      "the training cost after 18000 iteration is 0.771963:\n",
      "the training accuracy after 18000 iteration is     0.85:\n",
      "the validation cost after 18000 iteration is 1.395874:\n",
      "the validation accuracy after 18000 iteration is     0.55:\n",
      "the training cost after 18100 iteration is 0.900813:\n",
      "the training accuracy after 18100 iteration is     0.83:\n",
      "the validation cost after 18100 iteration is 1.417976:\n",
      "the validation accuracy after 18100 iteration is     0.54:\n",
      "the training cost after 18200 iteration is 0.950681:\n",
      "the training accuracy after 18200 iteration is     0.77:\n",
      "the validation cost after 18200 iteration is 1.392994:\n",
      "the validation accuracy after 18200 iteration is     0.53:\n",
      "the training cost after 18300 iteration is 0.866376:\n",
      "the training accuracy after 18300 iteration is     0.80:\n",
      "the validation cost after 18300 iteration is 1.403411:\n",
      "the validation accuracy after 18300 iteration is     0.55:\n",
      "the training cost after 18400 iteration is 1.046331:\n",
      "the training accuracy after 18400 iteration is     0.77:\n",
      "the validation cost after 18400 iteration is 1.435302:\n",
      "the validation accuracy after 18400 iteration is     0.53:\n",
      "the training cost after 18500 iteration is 0.675655:\n",
      "the training accuracy after 18500 iteration is     0.85:\n",
      "the validation cost after 18500 iteration is 1.412728:\n",
      "the validation accuracy after 18500 iteration is     0.54:\n",
      "the training cost after 18600 iteration is 0.811631:\n",
      "the training accuracy after 18600 iteration is     0.84:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation cost after 18600 iteration is 1.404643:\n",
      "the validation accuracy after 18600 iteration is     0.55:\n",
      "the training cost after 18700 iteration is 1.005366:\n",
      "the training accuracy after 18700 iteration is     0.76:\n",
      "the validation cost after 18700 iteration is 1.566663:\n",
      "the validation accuracy after 18700 iteration is     0.51:\n",
      "the training cost after 18800 iteration is 0.657855:\n",
      "the training accuracy after 18800 iteration is     0.88:\n",
      "the validation cost after 18800 iteration is 1.462443:\n",
      "the validation accuracy after 18800 iteration is     0.53:\n",
      "the training cost after 18900 iteration is 0.929890:\n",
      "the training accuracy after 18900 iteration is     0.81:\n",
      "the validation cost after 18900 iteration is 1.445576:\n",
      "the validation accuracy after 18900 iteration is     0.52:\n",
      "the training cost after 19000 iteration is 0.789939:\n",
      "the training accuracy after 19000 iteration is     0.87:\n",
      "the validation cost after 19000 iteration is 1.380618:\n",
      "the validation accuracy after 19000 iteration is     0.55:\n",
      "the training cost after 19100 iteration is 0.686938:\n",
      "the training accuracy after 19100 iteration is     0.88:\n",
      "the validation cost after 19100 iteration is 1.440984:\n",
      "the validation accuracy after 19100 iteration is     0.54:\n",
      "the training cost after 19200 iteration is 0.894131:\n",
      "the training accuracy after 19200 iteration is     0.79:\n",
      "the validation cost after 19200 iteration is 1.436353:\n",
      "the validation accuracy after 19200 iteration is     0.53:\n",
      "the training cost after 19300 iteration is 0.666416:\n",
      "the training accuracy after 19300 iteration is     0.88:\n",
      "the validation cost after 19300 iteration is 1.418610:\n",
      "the validation accuracy after 19300 iteration is     0.54:\n",
      "the training cost after 19400 iteration is 0.714110:\n",
      "the training accuracy after 19400 iteration is     0.85:\n",
      "the validation cost after 19400 iteration is 1.438194:\n",
      "the validation accuracy after 19400 iteration is     0.54:\n",
      "the training cost after 19500 iteration is 0.934414:\n",
      "the training accuracy after 19500 iteration is     0.73:\n",
      "the validation cost after 19500 iteration is 1.558324:\n",
      "the validation accuracy after 19500 iteration is     0.51:\n",
      "the training cost after 19600 iteration is 0.693830:\n",
      "the training accuracy after 19600 iteration is     0.80:\n",
      "the validation cost after 19600 iteration is 1.453781:\n",
      "the validation accuracy after 19600 iteration is     0.54:\n",
      "the training cost after 19700 iteration is 0.730829:\n",
      "the training accuracy after 19700 iteration is     0.89:\n",
      "the validation cost after 19700 iteration is 1.377756:\n",
      "the validation accuracy after 19700 iteration is     0.55:\n",
      "the training cost after 19800 iteration is 0.834088:\n",
      "the training accuracy after 19800 iteration is     0.83:\n",
      "the validation cost after 19800 iteration is 1.489600:\n",
      "the validation accuracy after 19800 iteration is     0.53:\n",
      "the training cost after 19900 iteration is 1.010937:\n",
      "the training accuracy after 19900 iteration is     0.73:\n",
      "the validation cost after 19900 iteration is 1.551807:\n",
      "the validation accuracy after 19900 iteration is     0.53:\n",
      "the training cost after 20000 iteration is 0.644537:\n",
      "the training accuracy after 20000 iteration is     0.88:\n",
      "the validation cost after 20000 iteration is 1.450293:\n",
      "the validation accuracy after 20000 iteration is     0.55:\n",
      "the training cost after 20100 iteration is 0.681431:\n",
      "the training accuracy after 20100 iteration is     0.88:\n",
      "the validation cost after 20100 iteration is 1.549549:\n",
      "the validation accuracy after 20100 iteration is     0.53:\n",
      "the training cost after 20200 iteration is 0.805965:\n",
      "the training accuracy after 20200 iteration is     0.88:\n",
      "the validation cost after 20200 iteration is 1.429768:\n",
      "the validation accuracy after 20200 iteration is     0.54:\n",
      "the training cost after 20300 iteration is 0.658757:\n",
      "the training accuracy after 20300 iteration is     0.83:\n",
      "the validation cost after 20300 iteration is 1.570896:\n",
      "the validation accuracy after 20300 iteration is     0.53:\n",
      "the training cost after 20400 iteration is 0.581411:\n",
      "the training accuracy after 20400 iteration is     0.91:\n",
      "the validation cost after 20400 iteration is 1.460466:\n",
      "the validation accuracy after 20400 iteration is     0.55:\n",
      "the training cost after 20500 iteration is 0.627421:\n",
      "the training accuracy after 20500 iteration is     0.90:\n",
      "the validation cost after 20500 iteration is 1.514160:\n",
      "the validation accuracy after 20500 iteration is     0.53:\n",
      "the training cost after 20600 iteration is 0.571470:\n",
      "the training accuracy after 20600 iteration is     0.88:\n",
      "the validation cost after 20600 iteration is 1.497619:\n",
      "the validation accuracy after 20600 iteration is     0.55:\n",
      "the training cost after 20700 iteration is 0.739246:\n",
      "the training accuracy after 20700 iteration is     0.82:\n",
      "the validation cost after 20700 iteration is 1.458801:\n",
      "the validation accuracy after 20700 iteration is     0.55:\n",
      "the training cost after 20800 iteration is 0.817194:\n",
      "the training accuracy after 20800 iteration is     0.78:\n",
      "the validation cost after 20800 iteration is 1.515156:\n",
      "the validation accuracy after 20800 iteration is     0.52:\n",
      "the training cost after 20900 iteration is 0.741758:\n",
      "the training accuracy after 20900 iteration is     0.88:\n",
      "the validation cost after 20900 iteration is 1.478523:\n",
      "the validation accuracy after 20900 iteration is     0.54:\n",
      "the training cost after 21000 iteration is 0.692670:\n",
      "the training accuracy after 21000 iteration is     0.89:\n",
      "the validation cost after 21000 iteration is 1.467875:\n",
      "the validation accuracy after 21000 iteration is     0.54:\n",
      "the training cost after 21100 iteration is 0.702617:\n",
      "the training accuracy after 21100 iteration is     0.83:\n",
      "the validation cost after 21100 iteration is 1.540100:\n",
      "the validation accuracy after 21100 iteration is     0.53:\n",
      "the training cost after 21200 iteration is 0.699714:\n",
      "the training accuracy after 21200 iteration is     0.88:\n",
      "the validation cost after 21200 iteration is 1.432608:\n",
      "the validation accuracy after 21200 iteration is     0.56:\n",
      "the training cost after 21300 iteration is 0.827855:\n",
      "the training accuracy after 21300 iteration is     0.80:\n",
      "the validation cost after 21300 iteration is 1.523943:\n",
      "the validation accuracy after 21300 iteration is     0.53:\n",
      "the training cost after 21400 iteration is 0.630251:\n",
      "the training accuracy after 21400 iteration is     0.89:\n",
      "the validation cost after 21400 iteration is 1.445272:\n",
      "the validation accuracy after 21400 iteration is     0.55:\n",
      "the training cost after 21500 iteration is 1.012138:\n",
      "the training accuracy after 21500 iteration is     0.70:\n",
      "the validation cost after 21500 iteration is 1.758124:\n",
      "the validation accuracy after 21500 iteration is     0.49:\n",
      "the training cost after 21600 iteration is 0.750781:\n",
      "the training accuracy after 21600 iteration is     0.88:\n",
      "the validation cost after 21600 iteration is 1.507221:\n",
      "the validation accuracy after 21600 iteration is     0.54:\n",
      "the training cost after 21700 iteration is 0.768697:\n",
      "the training accuracy after 21700 iteration is     0.85:\n",
      "the validation cost after 21700 iteration is 1.461297:\n",
      "the validation accuracy after 21700 iteration is     0.54:\n",
      "the training cost after 21800 iteration is 0.606033:\n",
      "the training accuracy after 21800 iteration is     0.92:\n",
      "the validation cost after 21800 iteration is 1.478086:\n",
      "the validation accuracy after 21800 iteration is     0.54:\n",
      "the training cost after 21900 iteration is 0.738107:\n",
      "the training accuracy after 21900 iteration is     0.87:\n",
      "the validation cost after 21900 iteration is 1.533128:\n",
      "the validation accuracy after 21900 iteration is     0.54:\n",
      "the training cost after 22000 iteration is 0.770011:\n",
      "the training accuracy after 22000 iteration is     0.81:\n",
      "the validation cost after 22000 iteration is 1.539569:\n",
      "the validation accuracy after 22000 iteration is     0.53:\n",
      "the training cost after 22100 iteration is 0.710456:\n",
      "the training accuracy after 22100 iteration is     0.88:\n",
      "the validation cost after 22100 iteration is 1.529019:\n",
      "the validation accuracy after 22100 iteration is     0.52:\n",
      "the training cost after 22200 iteration is 0.684773:\n",
      "the training accuracy after 22200 iteration is     0.84:\n",
      "the validation cost after 22200 iteration is 1.480078:\n",
      "the validation accuracy after 22200 iteration is     0.54:\n",
      "the training cost after 22300 iteration is 0.738821:\n",
      "the training accuracy after 22300 iteration is     0.82:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation cost after 22300 iteration is 1.549669:\n",
      "the validation accuracy after 22300 iteration is     0.52:\n",
      "the training cost after 22400 iteration is 0.813825:\n",
      "the training accuracy after 22400 iteration is     0.80:\n",
      "the validation cost after 22400 iteration is 1.560153:\n",
      "the validation accuracy after 22400 iteration is     0.53:\n",
      "the training cost after 22500 iteration is 0.562809:\n",
      "the training accuracy after 22500 iteration is     0.93:\n",
      "the validation cost after 22500 iteration is 1.499498:\n",
      "the validation accuracy after 22500 iteration is     0.55:\n",
      "the training cost after 22600 iteration is 0.662206:\n",
      "the training accuracy after 22600 iteration is     0.92:\n",
      "the validation cost after 22600 iteration is 1.502117:\n",
      "the validation accuracy after 22600 iteration is     0.55:\n",
      "the training cost after 22700 iteration is 0.562453:\n",
      "the training accuracy after 22700 iteration is     0.90:\n",
      "the validation cost after 22700 iteration is 1.532776:\n",
      "the validation accuracy after 22700 iteration is     0.55:\n",
      "the training cost after 22800 iteration is 0.601297:\n",
      "the training accuracy after 22800 iteration is     0.91:\n",
      "the validation cost after 22800 iteration is 1.545622:\n",
      "the validation accuracy after 22800 iteration is     0.55:\n",
      "the training cost after 22900 iteration is 0.685720:\n",
      "the training accuracy after 22900 iteration is     0.84:\n",
      "the validation cost after 22900 iteration is 1.548091:\n",
      "the validation accuracy after 22900 iteration is     0.54:\n",
      "the training cost after 23000 iteration is 0.792842:\n",
      "the training accuracy after 23000 iteration is     0.82:\n",
      "the validation cost after 23000 iteration is 1.666851:\n",
      "the validation accuracy after 23000 iteration is     0.52:\n",
      "the training cost after 23100 iteration is 0.650383:\n",
      "the training accuracy after 23100 iteration is     0.86:\n",
      "the validation cost after 23100 iteration is 1.490371:\n",
      "the validation accuracy after 23100 iteration is     0.54:\n",
      "the training cost after 23200 iteration is 0.914013:\n",
      "the training accuracy after 23200 iteration is     0.83:\n",
      "the validation cost after 23200 iteration is 1.623140:\n",
      "the validation accuracy after 23200 iteration is     0.52:\n",
      "the training cost after 23300 iteration is 0.776473:\n",
      "the training accuracy after 23300 iteration is     0.80:\n",
      "the validation cost after 23300 iteration is 1.710741:\n",
      "the validation accuracy after 23300 iteration is     0.51:\n",
      "the training cost after 23400 iteration is 0.670925:\n",
      "the training accuracy after 23400 iteration is     0.88:\n",
      "the validation cost after 23400 iteration is 1.513579:\n",
      "the validation accuracy after 23400 iteration is     0.54:\n",
      "the training cost after 23500 iteration is 1.009406:\n",
      "the training accuracy after 23500 iteration is     0.76:\n",
      "the validation cost after 23500 iteration is 1.769344:\n",
      "the validation accuracy after 23500 iteration is     0.50:\n",
      "the training cost after 23600 iteration is 0.775271:\n",
      "the training accuracy after 23600 iteration is     0.77:\n",
      "the validation cost after 23600 iteration is 1.676869:\n",
      "the validation accuracy after 23600 iteration is     0.52:\n",
      "the training cost after 23700 iteration is 0.538624:\n",
      "the training accuracy after 23700 iteration is     0.91:\n",
      "the validation cost after 23700 iteration is 1.491607:\n",
      "the validation accuracy after 23700 iteration is     0.56:\n",
      "the training cost after 23800 iteration is 0.580521:\n",
      "the training accuracy after 23800 iteration is     0.88:\n",
      "the validation cost after 23800 iteration is 1.506179:\n",
      "the validation accuracy after 23800 iteration is     0.55:\n",
      "the training cost after 23900 iteration is 0.476552:\n",
      "the training accuracy after 23900 iteration is     0.96:\n",
      "the validation cost after 23900 iteration is 1.509928:\n",
      "the validation accuracy after 23900 iteration is     0.55:\n",
      "the training cost after 24000 iteration is 0.555200:\n",
      "the training accuracy after 24000 iteration is     0.95:\n",
      "the validation cost after 24000 iteration is 1.564728:\n",
      "the validation accuracy after 24000 iteration is     0.55:\n",
      "the training cost after 24100 iteration is 0.710156:\n",
      "the training accuracy after 24100 iteration is     0.87:\n",
      "the validation cost after 24100 iteration is 1.629302:\n",
      "the validation accuracy after 24100 iteration is     0.52:\n",
      "the training cost after 24200 iteration is 0.699926:\n",
      "the training accuracy after 24200 iteration is     0.89:\n",
      "the validation cost after 24200 iteration is 1.683822:\n",
      "the validation accuracy after 24200 iteration is     0.52:\n",
      "the training cost after 24300 iteration is 0.573690:\n",
      "the training accuracy after 24300 iteration is     0.93:\n",
      "the validation cost after 24300 iteration is 1.541858:\n",
      "the validation accuracy after 24300 iteration is     0.54:\n",
      "the training cost after 24400 iteration is 0.774739:\n",
      "the training accuracy after 24400 iteration is     0.84:\n",
      "the validation cost after 24400 iteration is 1.621899:\n",
      "the validation accuracy after 24400 iteration is     0.53:\n",
      "the training cost after 24500 iteration is 0.617963:\n",
      "the training accuracy after 24500 iteration is     0.84:\n",
      "the validation cost after 24500 iteration is 1.617999:\n",
      "the validation accuracy after 24500 iteration is     0.53:\n",
      "the training cost after 24600 iteration is 0.976826:\n",
      "the training accuracy after 24600 iteration is     0.76:\n",
      "the validation cost after 24600 iteration is 1.805707:\n",
      "the validation accuracy after 24600 iteration is     0.50:\n",
      "the training cost after 24700 iteration is 0.706952:\n",
      "the training accuracy after 24700 iteration is     0.92:\n",
      "the validation cost after 24700 iteration is 1.541846:\n",
      "the validation accuracy after 24700 iteration is     0.55:\n",
      "the training cost after 24800 iteration is 0.550060:\n",
      "the training accuracy after 24800 iteration is     0.91:\n",
      "the validation cost after 24800 iteration is 1.667061:\n",
      "the validation accuracy after 24800 iteration is     0.52:\n",
      "the training cost after 24900 iteration is 0.669472:\n",
      "the training accuracy after 24900 iteration is     0.84:\n",
      "the validation cost after 24900 iteration is 1.676517:\n",
      "the validation accuracy after 24900 iteration is     0.53:\n",
      "the training cost after 25000 iteration is 0.716487:\n",
      "the training accuracy after 25000 iteration is     0.88:\n",
      "the validation cost after 25000 iteration is 1.752111:\n",
      "the validation accuracy after 25000 iteration is     0.52:\n",
      "the training cost after 25100 iteration is 0.642716:\n",
      "the training accuracy after 25100 iteration is     0.92:\n",
      "the validation cost after 25100 iteration is 1.625627:\n",
      "the validation accuracy after 25100 iteration is     0.53:\n",
      "the training cost after 25200 iteration is 1.464738:\n",
      "the training accuracy after 25200 iteration is     0.75:\n",
      "the validation cost after 25200 iteration is 1.715970:\n",
      "the validation accuracy after 25200 iteration is     0.49:\n",
      "the training cost after 25300 iteration is 0.613929:\n",
      "the training accuracy after 25300 iteration is     0.89:\n",
      "the validation cost after 25300 iteration is 1.594845:\n",
      "the validation accuracy after 25300 iteration is     0.54:\n",
      "the training cost after 25400 iteration is 1.193493:\n",
      "the training accuracy after 25400 iteration is     0.71:\n",
      "the validation cost after 25400 iteration is 1.941219:\n",
      "the validation accuracy after 25400 iteration is     0.48:\n",
      "the training cost after 25500 iteration is 0.699215:\n",
      "the training accuracy after 25500 iteration is     0.80:\n",
      "the validation cost after 25500 iteration is 1.772540:\n",
      "the validation accuracy after 25500 iteration is     0.51:\n",
      "the training cost after 25600 iteration is 0.508549:\n",
      "the training accuracy after 25600 iteration is     0.94:\n",
      "the validation cost after 25600 iteration is 1.582895:\n",
      "the validation accuracy after 25600 iteration is     0.55:\n",
      "the training cost after 25700 iteration is 0.617253:\n",
      "the training accuracy after 25700 iteration is     0.90:\n",
      "the validation cost after 25700 iteration is 1.640517:\n",
      "the validation accuracy after 25700 iteration is     0.54:\n",
      "the training cost after 25800 iteration is 0.698212:\n",
      "the training accuracy after 25800 iteration is     0.93:\n",
      "the validation cost after 25800 iteration is 1.691002:\n",
      "the validation accuracy after 25800 iteration is     0.53:\n",
      "the training cost after 25900 iteration is 0.720600:\n",
      "the training accuracy after 25900 iteration is     0.79:\n",
      "the validation cost after 25900 iteration is 1.826461:\n",
      "the validation accuracy after 25900 iteration is     0.50:\n",
      "the training cost after 26000 iteration is 0.556440:\n",
      "the training accuracy after 26000 iteration is     0.91:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation cost after 26000 iteration is 1.633303:\n",
      "the validation accuracy after 26000 iteration is     0.54:\n",
      "the training cost after 26100 iteration is 0.747287:\n",
      "the training accuracy after 26100 iteration is     0.82:\n",
      "the validation cost after 26100 iteration is 1.816938:\n",
      "the validation accuracy after 26100 iteration is     0.50:\n",
      "the training cost after 26200 iteration is 0.628180:\n",
      "the training accuracy after 26200 iteration is     0.88:\n",
      "the validation cost after 26200 iteration is 1.766357:\n",
      "the validation accuracy after 26200 iteration is     0.53:\n",
      "the training cost after 26300 iteration is 0.588795:\n",
      "the training accuracy after 26300 iteration is     0.90:\n",
      "the validation cost after 26300 iteration is 1.624907:\n",
      "the validation accuracy after 26300 iteration is     0.54:\n",
      "the training cost after 26400 iteration is 0.581008:\n",
      "the training accuracy after 26400 iteration is     0.91:\n",
      "the validation cost after 26400 iteration is 1.673911:\n",
      "the validation accuracy after 26400 iteration is     0.53:\n",
      "the training cost after 26500 iteration is 0.698942:\n",
      "the training accuracy after 26500 iteration is     0.85:\n",
      "the validation cost after 26500 iteration is 1.752596:\n",
      "the validation accuracy after 26500 iteration is     0.53:\n",
      "the training cost after 26600 iteration is 0.719456:\n",
      "the training accuracy after 26600 iteration is     0.80:\n",
      "the validation cost after 26600 iteration is 1.819485:\n",
      "the validation accuracy after 26600 iteration is     0.52:\n",
      "the training cost after 26700 iteration is 0.676843:\n",
      "the training accuracy after 26700 iteration is     0.84:\n",
      "the validation cost after 26700 iteration is 1.825332:\n",
      "the validation accuracy after 26700 iteration is     0.51:\n",
      "the training cost after 26800 iteration is 0.678203:\n",
      "the training accuracy after 26800 iteration is     0.81:\n",
      "the validation cost after 26800 iteration is 1.730470:\n",
      "the validation accuracy after 26800 iteration is     0.53:\n",
      "the training cost after 26900 iteration is 1.121630:\n",
      "the training accuracy after 26900 iteration is     0.70:\n",
      "the validation cost after 26900 iteration is 2.065374:\n",
      "the validation accuracy after 26900 iteration is     0.46:\n",
      "the training cost after 27000 iteration is 0.493304:\n",
      "the training accuracy after 27000 iteration is     0.92:\n",
      "the validation cost after 27000 iteration is 1.656645:\n",
      "the validation accuracy after 27000 iteration is     0.54:\n",
      "the training cost after 27100 iteration is 0.500078:\n",
      "the training accuracy after 27100 iteration is     0.93:\n",
      "the validation cost after 27100 iteration is 1.610145:\n",
      "the validation accuracy after 27100 iteration is     0.54:\n",
      "the training cost after 27200 iteration is 0.686239:\n",
      "the training accuracy after 27200 iteration is     0.87:\n",
      "the validation cost after 27200 iteration is 1.823941:\n",
      "the validation accuracy after 27200 iteration is     0.53:\n",
      "the training cost after 27300 iteration is 0.513979:\n",
      "the training accuracy after 27300 iteration is     0.91:\n",
      "the validation cost after 27300 iteration is 1.694940:\n",
      "the validation accuracy after 27300 iteration is     0.54:\n",
      "the training cost after 27400 iteration is 0.697780:\n",
      "the training accuracy after 27400 iteration is     0.86:\n",
      "the validation cost after 27400 iteration is 1.773996:\n",
      "the validation accuracy after 27400 iteration is     0.53:\n",
      "the training cost after 27500 iteration is 0.514749:\n",
      "the training accuracy after 27500 iteration is     0.94:\n",
      "the validation cost after 27500 iteration is 1.645211:\n",
      "the validation accuracy after 27500 iteration is     0.55:\n",
      "the training cost after 27600 iteration is 0.435509:\n",
      "the training accuracy after 27600 iteration is     0.93:\n",
      "the validation cost after 27600 iteration is 1.688793:\n",
      "the validation accuracy after 27600 iteration is     0.54:\n",
      "the training cost after 27700 iteration is 0.679372:\n",
      "the training accuracy after 27700 iteration is     0.90:\n",
      "the validation cost after 27700 iteration is 1.629748:\n",
      "the validation accuracy after 27700 iteration is     0.56:\n",
      "the training cost after 27800 iteration is 0.492070:\n",
      "the training accuracy after 27800 iteration is     0.96:\n",
      "the validation cost after 27800 iteration is 1.662521:\n",
      "the validation accuracy after 27800 iteration is     0.55:\n",
      "the training cost after 27900 iteration is 0.498981:\n",
      "the training accuracy after 27900 iteration is     0.95:\n",
      "the validation cost after 27900 iteration is 1.672102:\n",
      "the validation accuracy after 27900 iteration is     0.55:\n",
      "the training cost after 28000 iteration is 0.612818:\n",
      "the training accuracy after 28000 iteration is     0.91:\n",
      "the validation cost after 28000 iteration is 1.821467:\n",
      "the validation accuracy after 28000 iteration is     0.52:\n",
      "the training cost after 28100 iteration is 0.510580:\n",
      "the training accuracy after 28100 iteration is     0.93:\n",
      "the validation cost after 28100 iteration is 1.757940:\n",
      "the validation accuracy after 28100 iteration is     0.53:\n",
      "the training cost after 28200 iteration is 0.544188:\n",
      "the training accuracy after 28200 iteration is     0.94:\n",
      "the validation cost after 28200 iteration is 1.707951:\n",
      "the validation accuracy after 28200 iteration is     0.53:\n",
      "the training cost after 28300 iteration is 0.583416:\n",
      "the training accuracy after 28300 iteration is     0.82:\n",
      "the validation cost after 28300 iteration is 1.893641:\n",
      "the validation accuracy after 28300 iteration is     0.51:\n",
      "the training cost after 28400 iteration is 0.418256:\n",
      "the training accuracy after 28400 iteration is     0.95:\n",
      "the validation cost after 28400 iteration is 1.668105:\n",
      "the validation accuracy after 28400 iteration is     0.54:\n",
      "the training cost after 28500 iteration is 0.567617:\n",
      "the training accuracy after 28500 iteration is     0.91:\n",
      "the validation cost after 28500 iteration is 1.742305:\n",
      "the validation accuracy after 28500 iteration is     0.54:\n",
      "the training cost after 28600 iteration is 0.617920:\n",
      "the training accuracy after 28600 iteration is     0.82:\n",
      "the validation cost after 28600 iteration is 1.835450:\n",
      "the validation accuracy after 28600 iteration is     0.52:\n",
      "the training cost after 28700 iteration is 0.497802:\n",
      "the training accuracy after 28700 iteration is     0.96:\n",
      "the validation cost after 28700 iteration is 1.856583:\n",
      "the validation accuracy after 28700 iteration is     0.54:\n",
      "the training cost after 28800 iteration is 0.466537:\n",
      "the training accuracy after 28800 iteration is     0.95:\n",
      "the validation cost after 28800 iteration is 1.710939:\n",
      "the validation accuracy after 28800 iteration is     0.55:\n",
      "the training cost after 28900 iteration is 1.016861:\n",
      "the training accuracy after 28900 iteration is     0.83:\n",
      "the validation cost after 28900 iteration is 2.166462:\n",
      "the validation accuracy after 28900 iteration is     0.47:\n",
      "the training cost after 29000 iteration is 0.567485:\n",
      "the training accuracy after 29000 iteration is     0.91:\n",
      "the validation cost after 29000 iteration is 1.746342:\n",
      "the validation accuracy after 29000 iteration is     0.53:\n",
      "the training cost after 29100 iteration is 0.505867:\n",
      "the training accuracy after 29100 iteration is     0.86:\n",
      "the validation cost after 29100 iteration is 1.864909:\n",
      "the validation accuracy after 29100 iteration is     0.52:\n",
      "the training cost after 29200 iteration is 0.530158:\n",
      "the training accuracy after 29200 iteration is     0.93:\n",
      "the validation cost after 29200 iteration is 1.782811:\n",
      "the validation accuracy after 29200 iteration is     0.54:\n",
      "the training cost after 29300 iteration is 0.472126:\n",
      "the training accuracy after 29300 iteration is     0.95:\n",
      "the validation cost after 29300 iteration is 1.746607:\n",
      "the validation accuracy after 29300 iteration is     0.54:\n",
      "the training cost after 29400 iteration is 0.540676:\n",
      "the training accuracy after 29400 iteration is     0.90:\n",
      "the validation cost after 29400 iteration is 1.823073:\n",
      "the validation accuracy after 29400 iteration is     0.53:\n",
      "the training cost after 29500 iteration is 0.327271:\n",
      "the training accuracy after 29500 iteration is     0.99:\n",
      "the validation cost after 29500 iteration is 1.738241:\n",
      "the validation accuracy after 29500 iteration is     0.54:\n",
      "the training cost after 29600 iteration is 0.544837:\n",
      "the training accuracy after 29600 iteration is     0.95:\n",
      "the validation cost after 29600 iteration is 1.999083:\n",
      "the validation accuracy after 29600 iteration is     0.52:\n",
      "the training cost after 29700 iteration is 0.576999:\n",
      "the training accuracy after 29700 iteration is     0.92:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation cost after 29700 iteration is 1.758737:\n",
      "the validation accuracy after 29700 iteration is     0.55:\n",
      "the training cost after 29800 iteration is 0.317334:\n",
      "the training accuracy after 29800 iteration is     0.99:\n",
      "the validation cost after 29800 iteration is 1.777000:\n",
      "the validation accuracy after 29800 iteration is     0.55:\n",
      "the training cost after 29900 iteration is 0.437544:\n",
      "the training accuracy after 29900 iteration is     0.96:\n",
      "the validation cost after 29900 iteration is 1.795926:\n",
      "the validation accuracy after 29900 iteration is     0.54:\n"
     ]
    }
   ],
   "source": [
    "# try train, you can adjust your hyperparameter here, and plot the it on the next block\n",
    "# this block withoout regulization\n",
    "# layer_dimensions = [X_train.shape[0],512, 128, 32, 10]  # including the input and output layers\n",
    "# NN = NeuralNetwork(layer_dimensions)\n",
    "NN.train(X_train, y_train, X_validation, y_validation,iters=30000, alpha=0.03, batch_size=128, print_every=100)\n",
    "# now alpha = 0.01 for 30000, and alpha = 0.003 for 30000, and alpha = 0.001 for 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqOBXFEVJMf4fJRIQrLuQdXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b4225f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTNwNwzCykP8HvDXQbCss3VIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106a16ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on the validation set is:0.5298\n"
     ]
    }
   ],
   "source": [
    "# plot the result here\n",
    "plt.title(\"cost\")\n",
    "plt.plot(NN.train_cost,'r--', NN.validation_cost, 'bs')\n",
    "plt.show()\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(NN.train_accuracy,'r--', NN.validation_accuracy, 'bs')\n",
    "plt.show()\n",
    "y_predict_validation = NN.predict(X_validation)\n",
    "accuracy = np.sum((y_predict_validation == y_validation) * 1) / len(y_validation)\n",
    "print('the accuracy on the validation set is:' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training cost after 0000 iteration is 0.987924:\n",
      "the training accuracy after 0000 iteration is     0.75:\n",
      "the validation cost after 0000 iteration is 1.299282:\n",
      "the validation accuracy after 0000 iteration is     0.55:\n",
      "the training cost after 0100 iteration is 0.892887:\n",
      "the training accuracy after 0100 iteration is     0.79:\n",
      "the validation cost after 0100 iteration is 1.282282:\n",
      "the validation accuracy after 0100 iteration is     0.56:\n",
      "the training cost after 0200 iteration is 1.256956:\n",
      "the training accuracy after 0200 iteration is     0.69:\n",
      "the validation cost after 0200 iteration is 1.279908:\n",
      "the validation accuracy after 0200 iteration is     0.56:\n",
      "the training cost after 0300 iteration is 1.053183:\n",
      "the training accuracy after 0300 iteration is     0.75:\n",
      "the validation cost after 0300 iteration is 1.285948:\n",
      "the validation accuracy after 0300 iteration is     0.56:\n",
      "the training cost after 0400 iteration is 1.011604:\n",
      "the training accuracy after 0400 iteration is     0.77:\n",
      "the validation cost after 0400 iteration is 1.287534:\n",
      "the validation accuracy after 0400 iteration is     0.56:\n",
      "the training cost after 0500 iteration is 1.066936:\n",
      "the training accuracy after 0500 iteration is     0.73:\n",
      "the validation cost after 0500 iteration is 1.268154:\n",
      "the validation accuracy after 0500 iteration is     0.57:\n",
      "the training cost after 0600 iteration is 0.904733:\n",
      "the training accuracy after 0600 iteration is     0.79:\n",
      "the validation cost after 0600 iteration is 1.285765:\n",
      "the validation accuracy after 0600 iteration is     0.56:\n",
      "the training cost after 0700 iteration is 1.057444:\n",
      "the training accuracy after 0700 iteration is     0.79:\n",
      "the validation cost after 0700 iteration is 1.267681:\n",
      "the validation accuracy after 0700 iteration is     0.57:\n",
      "the training cost after 0800 iteration is 1.032567:\n",
      "the training accuracy after 0800 iteration is     0.76:\n",
      "the validation cost after 0800 iteration is 1.276888:\n",
      "the validation accuracy after 0800 iteration is     0.56:\n",
      "the training cost after 0900 iteration is 0.860805:\n",
      "the training accuracy after 0900 iteration is     0.77:\n",
      "the validation cost after 0900 iteration is 1.278375:\n",
      "the validation accuracy after 0900 iteration is     0.56:\n",
      "the training cost after 1000 iteration is 0.953870:\n",
      "the training accuracy after 1000 iteration is     0.81:\n",
      "the validation cost after 1000 iteration is 1.286435:\n",
      "the validation accuracy after 1000 iteration is     0.56:\n",
      "the training cost after 1100 iteration is 0.984201:\n",
      "the training accuracy after 1100 iteration is     0.71:\n",
      "the validation cost after 1100 iteration is 1.290253:\n",
      "the validation accuracy after 1100 iteration is     0.56:\n",
      "the training cost after 1200 iteration is 1.123946:\n",
      "the training accuracy after 1200 iteration is     0.75:\n",
      "the validation cost after 1200 iteration is 1.275620:\n",
      "the validation accuracy after 1200 iteration is     0.56:\n",
      "the training cost after 1300 iteration is 0.877577:\n",
      "the training accuracy after 1300 iteration is     0.82:\n",
      "the validation cost after 1300 iteration is 1.283714:\n",
      "the validation accuracy after 1300 iteration is     0.56:\n",
      "the training cost after 1400 iteration is 0.791095:\n",
      "the training accuracy after 1400 iteration is     0.85:\n",
      "the validation cost after 1400 iteration is 1.283714:\n",
      "the validation accuracy after 1400 iteration is     0.56:\n",
      "the training cost after 1500 iteration is 1.170705:\n",
      "the training accuracy after 1500 iteration is     0.67:\n",
      "the validation cost after 1500 iteration is 1.271016:\n",
      "the validation accuracy after 1500 iteration is     0.57:\n",
      "the training cost after 1600 iteration is 1.040469:\n",
      "the training accuracy after 1600 iteration is     0.70:\n",
      "the validation cost after 1600 iteration is 1.277143:\n",
      "the validation accuracy after 1600 iteration is     0.56:\n",
      "the training cost after 1700 iteration is 0.958161:\n",
      "the training accuracy after 1700 iteration is     0.73:\n",
      "the validation cost after 1700 iteration is 1.288759:\n",
      "the validation accuracy after 1700 iteration is     0.55:\n",
      "the training cost after 1800 iteration is 1.049138:\n",
      "the training accuracy after 1800 iteration is     0.79:\n",
      "the validation cost after 1800 iteration is 1.279961:\n",
      "the validation accuracy after 1800 iteration is     0.56:\n",
      "the training cost after 1900 iteration is 0.931282:\n",
      "the training accuracy after 1900 iteration is     0.74:\n",
      "the validation cost after 1900 iteration is 1.276585:\n",
      "the validation accuracy after 1900 iteration is     0.56:\n",
      "the training cost after 2000 iteration is 1.043279:\n",
      "the training accuracy after 2000 iteration is     0.77:\n",
      "the validation cost after 2000 iteration is 1.280563:\n",
      "the validation accuracy after 2000 iteration is     0.56:\n",
      "the training cost after 2100 iteration is 0.907839:\n",
      "the training accuracy after 2100 iteration is     0.83:\n",
      "the validation cost after 2100 iteration is 1.285161:\n",
      "the validation accuracy after 2100 iteration is     0.56:\n",
      "the training cost after 2200 iteration is 0.950010:\n",
      "the training accuracy after 2200 iteration is     0.76:\n",
      "the validation cost after 2200 iteration is 1.280017:\n",
      "the validation accuracy after 2200 iteration is     0.57:\n",
      "the training cost after 2300 iteration is 0.878192:\n",
      "the training accuracy after 2300 iteration is     0.82:\n",
      "the validation cost after 2300 iteration is 1.277314:\n",
      "the validation accuracy after 2300 iteration is     0.57:\n",
      "the training cost after 2400 iteration is 0.838362:\n",
      "the training accuracy after 2400 iteration is     0.78:\n",
      "the validation cost after 2400 iteration is 1.288718:\n",
      "the validation accuracy after 2400 iteration is     0.56:\n",
      "the training cost after 2500 iteration is 0.804504:\n",
      "the training accuracy after 2500 iteration is     0.80:\n",
      "the validation cost after 2500 iteration is 1.273230:\n",
      "the validation accuracy after 2500 iteration is     0.56:\n",
      "the training cost after 2600 iteration is 0.762276:\n",
      "the training accuracy after 2600 iteration is     0.82:\n",
      "the validation cost after 2600 iteration is 1.285516:\n",
      "the validation accuracy after 2600 iteration is     0.57:\n",
      "the training cost after 2700 iteration is 0.917933:\n",
      "the training accuracy after 2700 iteration is     0.78:\n",
      "the validation cost after 2700 iteration is 1.274031:\n",
      "the validation accuracy after 2700 iteration is     0.56:\n",
      "the training cost after 2800 iteration is 0.881789:\n",
      "the training accuracy after 2800 iteration is     0.82:\n",
      "the validation cost after 2800 iteration is 1.300996:\n",
      "the validation accuracy after 2800 iteration is     0.56:\n",
      "the training cost after 2900 iteration is 0.954454:\n",
      "the training accuracy after 2900 iteration is     0.75:\n",
      "the validation cost after 2900 iteration is 1.287605:\n",
      "the validation accuracy after 2900 iteration is     0.56:\n",
      "the training cost after 3000 iteration is 0.952122:\n",
      "the training accuracy after 3000 iteration is     0.81:\n",
      "the validation cost after 3000 iteration is 1.302414:\n",
      "the validation accuracy after 3000 iteration is     0.56:\n",
      "the training cost after 3100 iteration is 0.917123:\n",
      "the training accuracy after 3100 iteration is     0.74:\n",
      "the validation cost after 3100 iteration is 1.284750:\n",
      "the validation accuracy after 3100 iteration is     0.56:\n",
      "the training cost after 3200 iteration is 0.890468:\n",
      "the training accuracy after 3200 iteration is     0.76:\n",
      "the validation cost after 3200 iteration is 1.299359:\n",
      "the validation accuracy after 3200 iteration is     0.56:\n",
      "the training cost after 3300 iteration is 0.822313:\n",
      "the training accuracy after 3300 iteration is     0.80:\n",
      "the validation cost after 3300 iteration is 1.275195:\n",
      "the validation accuracy after 3300 iteration is     0.56:\n",
      "the training cost after 3400 iteration is 1.018050:\n",
      "the training accuracy after 3400 iteration is     0.77:\n",
      "the validation cost after 3400 iteration is 1.288240:\n",
      "the validation accuracy after 3400 iteration is     0.56:\n",
      "the training cost after 3500 iteration is 0.748734:\n",
      "the training accuracy after 3500 iteration is     0.84:\n",
      "the validation cost after 3500 iteration is 1.275252:\n",
      "the validation accuracy after 3500 iteration is     0.57:\n",
      "the training cost after 3600 iteration is 0.984173:\n",
      "the training accuracy after 3600 iteration is     0.77:\n",
      "the validation cost after 3600 iteration is 1.287425:\n",
      "the validation accuracy after 3600 iteration is     0.56:\n",
      "the training cost after 3700 iteration is 0.869058:\n",
      "the training accuracy after 3700 iteration is     0.79:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the validation cost after 3700 iteration is 1.314149:\n",
      "the validation accuracy after 3700 iteration is     0.56:\n",
      "the training cost after 3800 iteration is 0.959999:\n",
      "the training accuracy after 3800 iteration is     0.73:\n",
      "the validation cost after 3800 iteration is 1.286299:\n",
      "the validation accuracy after 3800 iteration is     0.56:\n",
      "the training cost after 3900 iteration is 0.833135:\n",
      "the training accuracy after 3900 iteration is     0.75:\n",
      "the validation cost after 3900 iteration is 1.291842:\n",
      "the validation accuracy after 3900 iteration is     0.56:\n",
      "the training cost after 4000 iteration is 1.094595:\n",
      "the training accuracy after 4000 iteration is     0.72:\n",
      "the validation cost after 4000 iteration is 1.301411:\n",
      "the validation accuracy after 4000 iteration is     0.56:\n",
      "the training cost after 4100 iteration is 1.112215:\n",
      "the training accuracy after 4100 iteration is     0.70:\n",
      "the validation cost after 4100 iteration is 1.295544:\n",
      "the validation accuracy after 4100 iteration is     0.57:\n",
      "the training cost after 4200 iteration is 0.809365:\n",
      "the training accuracy after 4200 iteration is     0.84:\n",
      "the validation cost after 4200 iteration is 1.286270:\n",
      "the validation accuracy after 4200 iteration is     0.56:\n",
      "the training cost after 4300 iteration is 0.890270:\n",
      "the training accuracy after 4300 iteration is     0.77:\n",
      "the validation cost after 4300 iteration is 1.289223:\n",
      "the validation accuracy after 4300 iteration is     0.56:\n",
      "the training cost after 4400 iteration is 0.746862:\n",
      "the training accuracy after 4400 iteration is     0.83:\n",
      "the validation cost after 4400 iteration is 1.296296:\n",
      "the validation accuracy after 4400 iteration is     0.57:\n",
      "the training cost after 4500 iteration is 0.895813:\n",
      "the training accuracy after 4500 iteration is     0.77:\n",
      "the validation cost after 4500 iteration is 1.300101:\n",
      "the validation accuracy after 4500 iteration is     0.56:\n",
      "the training cost after 4600 iteration is 0.919375:\n",
      "the training accuracy after 4600 iteration is     0.77:\n",
      "the validation cost after 4600 iteration is 1.295397:\n",
      "the validation accuracy after 4600 iteration is     0.56:\n",
      "the training cost after 4700 iteration is 0.912691:\n",
      "the training accuracy after 4700 iteration is     0.77:\n",
      "the validation cost after 4700 iteration is 1.282487:\n",
      "the validation accuracy after 4700 iteration is     0.56:\n",
      "the training cost after 4800 iteration is 1.067713:\n",
      "the training accuracy after 4800 iteration is     0.77:\n",
      "the validation cost after 4800 iteration is 1.280294:\n",
      "the validation accuracy after 4800 iteration is     0.56:\n",
      "the training cost after 4900 iteration is 0.904859:\n",
      "the training accuracy after 4900 iteration is     0.78:\n",
      "the validation cost after 4900 iteration is 1.299333:\n",
      "the validation accuracy after 4900 iteration is     0.56:\n",
      "the training cost after 5000 iteration is 0.783122:\n",
      "the training accuracy after 5000 iteration is     0.82:\n",
      "the validation cost after 5000 iteration is 1.288121:\n",
      "the validation accuracy after 5000 iteration is     0.56:\n",
      "the training cost after 5100 iteration is 0.877211:\n",
      "the training accuracy after 5100 iteration is     0.73:\n",
      "the validation cost after 5100 iteration is 1.281871:\n",
      "the validation accuracy after 5100 iteration is     0.57:\n",
      "the training cost after 5200 iteration is 0.872087:\n",
      "the training accuracy after 5200 iteration is     0.79:\n",
      "the validation cost after 5200 iteration is 1.280568:\n",
      "the validation accuracy after 5200 iteration is     0.56:\n",
      "the training cost after 5300 iteration is 0.986142:\n",
      "the training accuracy after 5300 iteration is     0.78:\n",
      "the validation cost after 5300 iteration is 1.284243:\n",
      "the validation accuracy after 5300 iteration is     0.56:\n",
      "the training cost after 5400 iteration is 1.040336:\n",
      "the training accuracy after 5400 iteration is     0.74:\n",
      "the validation cost after 5400 iteration is 1.286942:\n",
      "the validation accuracy after 5400 iteration is     0.56:\n",
      "the training cost after 5500 iteration is 0.747368:\n",
      "the training accuracy after 5500 iteration is     0.80:\n",
      "the validation cost after 5500 iteration is 1.283274:\n",
      "the validation accuracy after 5500 iteration is     0.56:\n",
      "the training cost after 5600 iteration is 0.869006:\n",
      "the training accuracy after 5600 iteration is     0.73:\n",
      "the validation cost after 5600 iteration is 1.294484:\n",
      "the validation accuracy after 5600 iteration is     0.56:\n",
      "the training cost after 5700 iteration is 1.051505:\n",
      "the training accuracy after 5700 iteration is     0.75:\n",
      "the validation cost after 5700 iteration is 1.306941:\n",
      "the validation accuracy after 5700 iteration is     0.56:\n",
      "the training cost after 5800 iteration is 0.799262:\n",
      "the training accuracy after 5800 iteration is     0.78:\n",
      "the validation cost after 5800 iteration is 1.295064:\n",
      "the validation accuracy after 5800 iteration is     0.56:\n",
      "the training cost after 5900 iteration is 1.034659:\n",
      "the training accuracy after 5900 iteration is     0.77:\n",
      "the validation cost after 5900 iteration is 1.313518:\n",
      "the validation accuracy after 5900 iteration is     0.56:\n",
      "the training cost after 6000 iteration is 1.046692:\n",
      "the training accuracy after 6000 iteration is     0.76:\n",
      "the validation cost after 6000 iteration is 1.293478:\n",
      "the validation accuracy after 6000 iteration is     0.56:\n",
      "the training cost after 6100 iteration is 1.015744:\n",
      "the training accuracy after 6100 iteration is     0.77:\n",
      "the validation cost after 6100 iteration is 1.301806:\n",
      "the validation accuracy after 6100 iteration is     0.56:\n",
      "the training cost after 6200 iteration is 0.877635:\n",
      "the training accuracy after 6200 iteration is     0.84:\n",
      "the validation cost after 6200 iteration is 1.295799:\n",
      "the validation accuracy after 6200 iteration is     0.56:\n",
      "the training cost after 6300 iteration is 1.053495:\n",
      "the training accuracy after 6300 iteration is     0.77:\n",
      "the validation cost after 6300 iteration is 1.291614:\n",
      "the validation accuracy after 6300 iteration is     0.56:\n",
      "the training cost after 6400 iteration is 1.015743:\n",
      "the training accuracy after 6400 iteration is     0.75:\n",
      "the validation cost after 6400 iteration is 1.309952:\n",
      "the validation accuracy after 6400 iteration is     0.56:\n",
      "the training cost after 6500 iteration is 0.894387:\n",
      "the training accuracy after 6500 iteration is     0.78:\n",
      "the validation cost after 6500 iteration is 1.294195:\n",
      "the validation accuracy after 6500 iteration is     0.56:\n",
      "the training cost after 6600 iteration is 0.915689:\n",
      "the training accuracy after 6600 iteration is     0.80:\n",
      "the validation cost after 6600 iteration is 1.298013:\n",
      "the validation accuracy after 6600 iteration is     0.56:\n",
      "the training cost after 6700 iteration is 0.922067:\n",
      "the training accuracy after 6700 iteration is     0.79:\n",
      "the validation cost after 6700 iteration is 1.288700:\n",
      "the validation accuracy after 6700 iteration is     0.56:\n",
      "the training cost after 6800 iteration is 0.842772:\n",
      "the training accuracy after 6800 iteration is     0.75:\n",
      "the validation cost after 6800 iteration is 1.294934:\n",
      "the validation accuracy after 6800 iteration is     0.56:\n",
      "the training cost after 6900 iteration is 0.933647:\n",
      "the training accuracy after 6900 iteration is     0.79:\n",
      "the validation cost after 6900 iteration is 1.276251:\n",
      "the validation accuracy after 6900 iteration is     0.56:\n",
      "the training cost after 7000 iteration is 0.831666:\n",
      "the training accuracy after 7000 iteration is     0.78:\n",
      "the validation cost after 7000 iteration is 1.309466:\n",
      "the validation accuracy after 7000 iteration is     0.56:\n",
      "the training cost after 7100 iteration is 0.948760:\n",
      "the training accuracy after 7100 iteration is     0.83:\n",
      "the validation cost after 7100 iteration is 1.311379:\n",
      "the validation accuracy after 7100 iteration is     0.56:\n",
      "the training cost after 7200 iteration is 0.901570:\n",
      "the training accuracy after 7200 iteration is     0.78:\n",
      "the validation cost after 7200 iteration is 1.289308:\n",
      "the validation accuracy after 7200 iteration is     0.56:\n",
      "the training cost after 7300 iteration is 0.814297:\n",
      "the training accuracy after 7300 iteration is     0.76:\n",
      "the validation cost after 7300 iteration is 1.295196:\n",
      "the validation accuracy after 7300 iteration is     0.56:\n",
      "the training cost after 7400 iteration is 0.852788:\n",
      "the training accuracy after 7400 iteration is     0.80:\n",
      "the validation cost after 7400 iteration is 1.290736:\n",
      "the validation accuracy after 7400 iteration is     0.56:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training cost after 7500 iteration is 1.032233:\n",
      "the training accuracy after 7500 iteration is     0.80:\n",
      "the validation cost after 7500 iteration is 1.292512:\n",
      "the validation accuracy after 7500 iteration is     0.57:\n",
      "the training cost after 7600 iteration is 0.951569:\n",
      "the training accuracy after 7600 iteration is     0.77:\n",
      "the validation cost after 7600 iteration is 1.286333:\n",
      "the validation accuracy after 7600 iteration is     0.56:\n",
      "the training cost after 7700 iteration is 0.952712:\n",
      "the training accuracy after 7700 iteration is     0.78:\n",
      "the validation cost after 7700 iteration is 1.295855:\n",
      "the validation accuracy after 7700 iteration is     0.56:\n",
      "the training cost after 7800 iteration is 0.895379:\n",
      "the training accuracy after 7800 iteration is     0.80:\n",
      "the validation cost after 7800 iteration is 1.283634:\n",
      "the validation accuracy after 7800 iteration is     0.56:\n",
      "the training cost after 7900 iteration is 0.829237:\n",
      "the training accuracy after 7900 iteration is     0.89:\n",
      "the validation cost after 7900 iteration is 1.291047:\n",
      "the validation accuracy after 7900 iteration is     0.57:\n",
      "the training cost after 8000 iteration is 0.991687:\n",
      "the training accuracy after 8000 iteration is     0.79:\n",
      "the validation cost after 8000 iteration is 1.306668:\n",
      "the validation accuracy after 8000 iteration is     0.56:\n",
      "the training cost after 8100 iteration is 0.925841:\n",
      "the training accuracy after 8100 iteration is     0.74:\n",
      "the validation cost after 8100 iteration is 1.302668:\n",
      "the validation accuracy after 8100 iteration is     0.56:\n",
      "the training cost after 8200 iteration is 1.018360:\n",
      "the training accuracy after 8200 iteration is     0.72:\n",
      "the validation cost after 8200 iteration is 1.317560:\n",
      "the validation accuracy after 8200 iteration is     0.56:\n",
      "the training cost after 8300 iteration is 0.765714:\n",
      "the training accuracy after 8300 iteration is     0.77:\n",
      "the validation cost after 8300 iteration is 1.292885:\n",
      "the validation accuracy after 8300 iteration is     0.56:\n",
      "the training cost after 8400 iteration is 0.800200:\n",
      "the training accuracy after 8400 iteration is     0.80:\n",
      "the validation cost after 8400 iteration is 1.302411:\n",
      "the validation accuracy after 8400 iteration is     0.56:\n",
      "the training cost after 8500 iteration is 0.959239:\n",
      "the training accuracy after 8500 iteration is     0.75:\n",
      "the validation cost after 8500 iteration is 1.303227:\n",
      "the validation accuracy after 8500 iteration is     0.57:\n",
      "the training cost after 8600 iteration is 0.699778:\n",
      "the training accuracy after 8600 iteration is     0.84:\n",
      "the validation cost after 8600 iteration is 1.303282:\n",
      "the validation accuracy after 8600 iteration is     0.56:\n",
      "the training cost after 8700 iteration is 0.862269:\n",
      "the training accuracy after 8700 iteration is     0.86:\n",
      "the validation cost after 8700 iteration is 1.304803:\n",
      "the validation accuracy after 8700 iteration is     0.56:\n",
      "the training cost after 8800 iteration is 0.901034:\n",
      "the training accuracy after 8800 iteration is     0.73:\n",
      "the validation cost after 8800 iteration is 1.300803:\n",
      "the validation accuracy after 8800 iteration is     0.56:\n",
      "the training cost after 8900 iteration is 0.974880:\n",
      "the training accuracy after 8900 iteration is     0.80:\n",
      "the validation cost after 8900 iteration is 1.303021:\n",
      "the validation accuracy after 8900 iteration is     0.55:\n",
      "the training cost after 9000 iteration is 1.003231:\n",
      "the training accuracy after 9000 iteration is     0.77:\n",
      "the validation cost after 9000 iteration is 1.306903:\n",
      "the validation accuracy after 9000 iteration is     0.57:\n",
      "the training cost after 9100 iteration is 1.071888:\n",
      "the training accuracy after 9100 iteration is     0.77:\n",
      "the validation cost after 9100 iteration is 1.284027:\n",
      "the validation accuracy after 9100 iteration is     0.56:\n",
      "the training cost after 9200 iteration is 0.956924:\n",
      "the training accuracy after 9200 iteration is     0.78:\n",
      "the validation cost after 9200 iteration is 1.301803:\n",
      "the validation accuracy after 9200 iteration is     0.56:\n",
      "the training cost after 9300 iteration is 0.969923:\n",
      "the training accuracy after 9300 iteration is     0.73:\n",
      "the validation cost after 9300 iteration is 1.316646:\n",
      "the validation accuracy after 9300 iteration is     0.56:\n",
      "the training cost after 9400 iteration is 1.031240:\n",
      "the training accuracy after 9400 iteration is     0.75:\n",
      "the validation cost after 9400 iteration is 1.292558:\n",
      "the validation accuracy after 9400 iteration is     0.56:\n",
      "the training cost after 9500 iteration is 0.861739:\n",
      "the training accuracy after 9500 iteration is     0.88:\n",
      "the validation cost after 9500 iteration is 1.313065:\n",
      "the validation accuracy after 9500 iteration is     0.56:\n",
      "the training cost after 9600 iteration is 0.689480:\n",
      "the training accuracy after 9600 iteration is     0.85:\n",
      "the validation cost after 9600 iteration is 1.296088:\n",
      "the validation accuracy after 9600 iteration is     0.57:\n",
      "the training cost after 9700 iteration is 0.919718:\n",
      "the training accuracy after 9700 iteration is     0.83:\n",
      "the validation cost after 9700 iteration is 1.298174:\n",
      "the validation accuracy after 9700 iteration is     0.56:\n",
      "the training cost after 9800 iteration is 0.823238:\n",
      "the training accuracy after 9800 iteration is     0.80:\n",
      "the validation cost after 9800 iteration is 1.300349:\n",
      "the validation accuracy after 9800 iteration is     0.56:\n",
      "the training cost after 9900 iteration is 0.965578:\n",
      "the training accuracy after 9900 iteration is     0.80:\n",
      "the validation cost after 9900 iteration is 1.289221:\n",
      "the validation accuracy after 9900 iteration is     0.56:\n"
     ]
    }
   ],
   "source": [
    "# this time train with L2 regulization\n",
    "# layer_dimensions = [X_train.shape[0], 512, 128, 32, 10]\n",
    "# NN2 = NeuralNetwork(layer_dimensions, drop_prob=0.2, reg_lambda=0)\n",
    "NN2.train(X_train, y_train, X_validation, y_validation, iters=10000, alpha=0.01, batch_size=128, print_every=100)\n",
    "# lambda 0.03, iterations 5000, alpha 0.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1811a4ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c3a0e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on the validation set is:0.5484\n"
     ]
    }
   ],
   "source": [
    "# plot the result here\n",
    "plt.title(\"cost\")\n",
    "plt.plot(NN2.train_cost,'r--', NN2.validation_cost, 'bs')\n",
    "plt.show()\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(NN2.train_accuracy,'r--', NN2.validation_accuracy, 'bs')\n",
    "plt.show()\n",
    "y_predict_validation = NN2.predict(X_validation)\n",
    "accuracy = np.sum((y_predict_validation == y_validation) * 1) / len(y_validation)\n",
    "print('the accuracy on the validation set is:' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions, DO NOT modify this\n",
    "\n",
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imread(path)\n",
    "\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to load data, DO NOT change these\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    y_one_hot[y] = 1\n",
    "    return y_one_hot.T\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = get_img_array(f)\n",
    "        img_arr = img_arr.flatten() / 255.0\n",
    "        images.append(img_arr)\n",
    "    X = np.column_stack(images)\n",
    "\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + 'train'\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "Loaded 10000/50000\n",
      "Loaded 20000/50000\n",
      "Loaded 30000/50000\n",
      "Loaded 40000/50000\n",
      "Loaded 50000/50000\n",
      "Loaded 10000/10000\n",
      "Data loading done\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_root_path = '/Users/zhengyixing/Documents/study/3nd_semester/DL/homework/cifar10-hw1/'\n",
    "X_train, y_train = get_train_data(data_root_path) # this may take a few minutes\n",
    "X_test = get_images(data_root_path + 'test')\n",
    "print('Data loading done')\n",
    "indexs = np.random.choice(50000, 5000, replace=False)\n",
    "X_validation = X_train[:,indexs]\n",
    "y_validation = y_train[indexs]\n",
    "X_train = np.delete(X_train,indexs, axis = 1)\n",
    "y_train = np.delete(y_train,indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 45000)\n",
      "(45000,)\n",
      "[6 6 6 ..., 5 1 3]\n",
      "45000\n",
      "(3072, 10000)\n",
      "(3072, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train)\n",
    "print(len(y_train))\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "# try train \n",
    "# layer_dimensions = [X_train.shape[0], 32, 10]  # including the input and output layers\n",
    "# NN = NeuralNetwork(layer_dimensions)\n",
    "# NN.train(X_train, y_train, iters=1000, alpha=0.0001, batch_size=100, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "#### Simple fully-connected deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_dimensions = [X_train.shape[0], ..., 10]  # including the input and output layers\n",
    "NN = NeuralNetwork(layer_dimensions)\n",
    "NN.train(X_train, y_train, iters=, alpha=, batch_size=, print_every=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_predicted = NN.predict(X_test)\n",
    "y_predicted, _ = NN.forwardPropagation(X_test)\n",
    "save_predictions('ans1-yz3065', y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test if your numpy file has been saved correctly\n",
    "loaded_y = np.load('ans1-uni.npy')\n",
    "print(loaded_y.shape)\n",
    "loaded_y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2: Regularizing the neural network\n",
    "#### Add dropout and L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN2 = NeuralNetwork(layer_dimensions, drop_prob=0, reg_lambda=0)\n",
    "# NN2.train(X_train, y_train, iters=1000, alpha=0.00001, batch_size=1000, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted2 = NN2.forwardPropagation(X_test)\n",
    "save_predictions('ans2-yz3065', y_predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
